<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://kabilanma.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://kabilanma.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2026-02-23T19:00:43+00:00</updated><id>https://kabilanma.github.io/feed.xml</id><title type="html">blank</title><subtitle>Computer Science Researcher in PL area. </subtitle><entry><title type="html">Hello World in MLIR</title><link href="https://kabilanma.github.io/blog/2026/MLIR-2/" rel="alternate" type="text/html" title="Hello World in MLIR"/><published>2026-02-13T06:01:00+00:00</published><updated>2026-02-13T06:01:00+00:00</updated><id>https://kabilanma.github.io/blog/2026/MLIR-2</id><content type="html" xml:base="https://kabilanma.github.io/blog/2026/MLIR-2/"><![CDATA[<h2 id="introduction">Introduction</h2> <hr/> <p>MLIR is not a programming language like C++ or Python; it is a compiler infrastructure—a framework of tools rather than a single tool. Because of this, there is no single “Hello World” program. As I’ve been learning, I’ve realized there are actually three different ways to use this framework, and you need to understand all of them.</p> <ol> <li>Write MLIR program directly using existing dialects.</li> <li>Create a MLIR pass for either optimization of analysis.</li> <li>Build our own dialects by extending the language itself by defining new operations and types.</li> </ol> <p>To really understand how MLIR works, I’m going to walk through a minimal “Hello World” for all three scenarios.</p> <h3 id="write-mlir-program">Write MLIR Program</h3> <p>The MLIR distribution includes a rich set of in-tree dialects, most of which target high-performance tensor compilers and hardware-specific code generation. However, before we tackle those, we need to understand the basics of the IR itself. We will start by manually writing a program using two core dialects: <code class="language-plaintext highlighter-rouge">func</code> (for function abstraction) and <code class="language-plaintext highlighter-rouge">arith</code> (for basic arithmetic operations). This will allow us to see how MLIR represents logic and how the infrastructure processes it without getting bogged down in complex types.</p> <p>Our goal is to get from high-level abstractions down to executable code. To do that, we’ll take a high-level MLIR program (using <code class="language-plaintext highlighter-rouge">func</code> and <code class="language-plaintext highlighter-rouge">arith</code>), lower it into MLIR’s LLVM Dialect, which is basically a 1:1 mapping of LLVM instructions inside MLIR, and finally translate that into pure LLVM IR (<code class="language-plaintext highlighter-rouge">.ll</code>) so the machine can actually run it. Our MLIR program should define a function which takes two integer (<code class="language-plaintext highlighter-rouge">i32</code>) arguments and add them together and return the results.</p> <p>In MLIR, everything is an operation. Operations are the core unit of abstraction and computation, similar in many ways to LLVM instructions. Even defining a function is an operation! The <code class="language-plaintext highlighter-rouge">func</code> dialect has an operation called <code class="language-plaintext highlighter-rouge">func</code> to define functions. We use the <code class="language-plaintext highlighter-rouge">@</code> sigil for global symbols (like function names) and the <code class="language-plaintext highlighter-rouge">%</code> sigil for local values (variables).</p> <div class="language-llvm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">func</span><span class="p">.</span><span class="err">func</span> <span class="vg">@add</span><span class="p">(</span><span class="nv">%arg0</span><span class="err">:</span> <span class="kt">i32</span><span class="p">,</span> <span class="nv">%arg1</span><span class="err">:</span> <span class="kt">i32</span><span class="p">)</span> <span class="err">-</span><span class="p">&gt;</span> <span class="kt">i32</span> <span class="p">{</span>
</code></pre></div></div> <p>This tells the compiler that we are defining a function called <code class="language-plaintext highlighter-rouge">@add</code> which takes two <code class="language-plaintext highlighter-rouge">i32</code> arguments <code class="language-plaintext highlighter-rouge">%arg0</code> and <code class="language-plaintext highlighter-rouge">%arg1</code> and returns a <code class="language-plaintext highlighter-rouge">i32</code> value.</p> <p>Now let’s take a look at the logic inside the block.</p> <div class="language-llvm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">func</span><span class="p">.</span><span class="err">func</span> <span class="vg">@add</span><span class="p">(</span><span class="nv">%arg0</span><span class="err">:</span> <span class="kt">i32</span><span class="p">,</span> <span class="nv">%arg1</span><span class="err">:</span> <span class="kt">i32</span><span class="p">)</span> <span class="err">-</span><span class="p">&gt;</span> <span class="kt">i32</span> <span class="p">{</span>
    <span class="nv">%0</span> <span class="p">=</span> <span class="err">arith</span><span class="p">.</span><span class="err">addi</span> <span class="nv">%arg0</span><span class="p">,</span> <span class="nv">%arg1</span> <span class="err">:</span> <span class="kt">i32</span>
    <span class="err">func</span><span class="p">.</span><span class="err">return</span> <span class="nv">%0</span> <span class="err">:</span> <span class="kt">i32</span>
<span class="p">}</span>
</code></pre></div></div> <p>Here, <code class="language-plaintext highlighter-rouge">arith.addi</code> does the heavy lifting. It grabs <code class="language-plaintext highlighter-rouge">%arg0</code> and <code class="language-plaintext highlighter-rouge">%arg1</code>, adds them up, and assigns the result to <code class="language-plaintext highlighter-rouge">%0</code>. Since every function block needs to end explicitly, we then use the <code class="language-plaintext highlighter-rouge">func.return</code> operation to send that <code class="language-plaintext highlighter-rouge">%0</code> value back out.</p> <p>Go ahead and save this code in a file called <code class="language-plaintext highlighter-rouge">add.mlir</code>. Next, we are going to use the <code class="language-plaintext highlighter-rouge">mlir-opt</code> tool to lower our high-level dialects (<code class="language-plaintext highlighter-rouge">func</code> and <code class="language-plaintext highlighter-rouge">arith</code>) down to the LLVM Dialect. If that sounds confusing, don’t worry, it tripped me up at first, too. You might be wondering: Why are we translating to an ‘LLVM dialect’ inside MLIR instead of just spitting out actual LLVM IR? &gt; That question actually hits on the entire purpose of MLIR. By keeping LLVM instructions represented as an MLIR dialect, the framework can preserve high-level structure and debug information during the translation process. The ultimate goal for almost any MLIR pipeline is to gradually step down the abstraction ladder until you hit this LLVM dialect. Once you are there, escaping out to standard LLVM IR is trivial.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlir-opt add.mlir <span class="nt">--convert-arith-to-llvm</span> <span class="nt">--convert-func-to-llvm</span> <span class="o">&gt;</span> add.llvm.mlir
</code></pre></div></div> <p>So, what is happening with this command?</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>func  ----
          \____ llvm
arith ----/
</code></pre></div></div> <p>As mentioned earlier, this process is called <strong>Lowering</strong>, where we are taking a MLIR program written using <code class="language-plaintext highlighter-rouge">func</code> and <code class="language-plaintext highlighter-rouge">arith</code> dialects and lower them into a single, lower-level dialect-<code class="language-plaintext highlighter-rouge">llvm</code>. You can use <code class="language-plaintext highlighter-rouge">mlir-opt --help</code> to look into all other possible <code class="language-plaintext highlighter-rouge">mlir-opt</code> flags.</p> <p>Now, ensure that you have the file <code class="language-plaintext highlighter-rouge">add.llvm.mlir</code>, which contains the translated code in the LLVM dialect as follows:</p> <div class="language-llvm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">module</span> <span class="p">{</span>
  <span class="err">llvm</span><span class="p">.</span><span class="err">func</span> <span class="vg">@add</span><span class="p">(</span><span class="nv">%arg0</span><span class="err">:</span> <span class="kt">i32</span><span class="p">,</span> <span class="nv">%arg1</span><span class="err">:</span> <span class="kt">i32</span><span class="p">)</span> <span class="err">-</span><span class="p">&gt;</span> <span class="kt">i32</span> <span class="p">{</span>
    <span class="nv">%0</span> <span class="p">=</span> <span class="err">llvm</span><span class="p">.</span><span class="k">add</span> <span class="nv">%arg0</span><span class="p">,</span> <span class="nv">%arg1</span> <span class="err">:</span> <span class="kt">i32</span>
    <span class="err">llvm</span><span class="p">.</span><span class="err">return</span> <span class="nv">%0</span> <span class="err">:</span> <span class="kt">i32</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>At first glance, it looks almost identical. But look closely at the prefixes. Every operation has shifted from a high-level abstraction to a specific LLVM instruction representation and now explictly wrapped in a <code class="language-plaintext highlighter-rouge">module</code>. In MLIR, operations cannot just float in the coid; they must live inside a block. Top-level operations like functions needs a container. The <code class="language-plaintext highlighter-rouge">module</code> operation acts as that container. Even though we did not explictly define a module ourselves, a <code class="language-plaintext highlighter-rouge">module</code> is implicit in MLIR programs which allows you to write top-level functions for convenience, but internally, it treats them as if they are inside a module. <code class="language-plaintext highlighter-rouge">module</code> defines a symbol table and creates a scope where global names (like <code class="language-plaintext highlighter-rouge">@add</code>) are defined and unique. This is roughly corresposnding to a translation unit in C++ or an object file. Our current program is entirly written using only one dialect-LLVM dialect and translated using <code class="language-plaintext highlighter-rouge">mlir-opt</code> as above.</p> <p>We are almost there. We have lowered out high-level logic into the low-level LLVM dialect. But here is the catch: we still cannot execute this. The machine does not know what MLIR is. It doesn’t know about dialects and operations. To run this, we need to leave the MLIR framework entirely and generate actual <strong>LLVM IR</strong>, the standard text-based format (<code class="language-plaintext highlighter-rouge">.ll</code>) that the LLVM backend understands.</p> <p>MLIR framework has a tool specifically for this purpose, <code class="language-plaintext highlighter-rouge">mlir-translate</code>. While <code class="language-plaintext highlighter-rouge">mlir-opt</code> is for transforming code within MLIR (optimization, lowering), <code class="language-plaintext highlighter-rouge">mlir-translate</code> is for exporting code out of MLIR. We will use <code class="language-plaintext highlighter-rouge">mlir-translate</code> to take out LLVM-dialect module and serialize it into valid LLVM IR using the following command:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlir-translate <span class="nt">--mlir-to-llvmir</span> add.llvm.mlir <span class="nt">-o</span> add.ll
</code></pre></div></div> <p>If you open <code class="language-plaintext highlighter-rouge">add.ll</code>, you will see something familiar to any compiler engineer: standard, raw LLVM IR. We now have <code class="language-plaintext highlighter-rouge">add.ll</code>, which contains our <code class="language-plaintext highlighter-rouge">@add</code> function in valid LLVM IR. But if you try to compile it directly, nothing will happen. Why? Because we don’t have a <code class="language-plaintext highlighter-rouge">main</code> function. Every C/C++ (and LLVM) programs needs an entry point. Our <code class="language-plaintext highlighter-rouge">@add</code> function is just a library function right now; it’s waiting to be called, but nobody is calling it. Therefore, let’s create a simple driver program to fix this problem.</p> <p>driver.ll</p> <div class="language-llvm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">; Declare the external 'add' function (it exists in our other file)</span>
<span class="k">declare</span> <span class="kt">i32</span> <span class="vg">@add</span><span class="p">(</span><span class="kt">i32</span><span class="p">,</span> <span class="kt">i32</span><span class="p">)</span>

<span class="k">define</span> <span class="kt">i32</span> <span class="vg">@main</span><span class="p">()</span> <span class="p">{</span>
  <span class="c1">; Call 'add' with arguments 10 and 32</span>
  <span class="nv">%result</span> <span class="p">=</span> <span class="k">call</span> <span class="kt">i32</span> <span class="vg">@add</span><span class="p">(</span><span class="kt">i32</span> <span class="m">10</span><span class="p">,</span> <span class="kt">i32</span> <span class="m">32</span><span class="p">)</span>
  
  <span class="c1">; Return the result as the exit code</span>
  <span class="k">ret</span> <span class="kt">i32</span> <span class="nv">%result</span>
<span class="p">}</span>
</code></pre></div></div> <p>This is raw LLVM IR. It tells the compiler: “There is a function called <code class="language-plaintext highlighter-rouge">@add</code> somewhere else. I want to call it with <code class="language-plaintext highlighter-rouge">10</code> and <code class="language-plaintext highlighter-rouge">32</code>, and I want to return the answer as my program’s exit code.” Now that we have the <code class="language-plaintext highlighter-rouge">main</code> function too, let’s use <code class="language-plaintext highlighter-rouge">clang</code> to link them together into a real executable binary and run it.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>clang add.ll driver.ll <span class="nt">-o</span> add
./add
</code></pre></div></div> <p>But wait!, where is the output? If you run it, you won’t see anything. That’s expected! We didn’t tell the program to print anything (which requires library calls like <code class="language-plaintext highlighter-rouge">printf</code>). We told it to return the results as the exit code. To see the exit code in your terminal, run this:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./add <span class="p">;</span> <span class="nb">echo</span> <span class="nv">$?</span>
</code></pre></div></div> <p>If everything worked, you should see: <code class="language-plaintext highlighter-rouge">42</code></p> <p>Success! We did it. We started with high-level MLIR (func + arith), lowered it to the LLVM dialect, translated it to LLVM IR, linked it with a driver, and executed it on the bare metal.</p> <p>You have officially written, compiled, and run your first MLIR program.</p> <h3 id="create-mlir-pass">Create MLIR Pass</h3> <p>This is where things get real. Writing MLIR code (<code class="language-plaintext highlighter-rouge">.mlir</code>) is like writing Python, you are a user. Writing a Pass means writing C++, you are now a compiler engineer. In this section, we aren’t just running <code class="language-plaintext highlighter-rouge">mlir-opt</code>; we are building our own version of it. If you have used LLVM before, the traditional workflow: compile your pass into a shared library (<code class="language-plaintext highlighter-rouge">.so</code>) and then load it dynamically into the standard <code class="language-plaintext highlighter-rouge">opt</code> tool using a flag like <code class="language-plaintext highlighter-rouge">-load-pass-plugin</code>. In MLIR, we rarely do that. Instead, we almost always build our own custom version of <code class="language-plaintext highlighter-rouge">mlir-opt</code>.</p> <p>Why? Because, MLIR relies heavily on C++ templates and static registration. Because of how C++ templates work, they don’t play nice across library boundaries, trying to load an MLIR pass dynamically can lead to weird ABI issues or missing symbols. So the “MLIR Way” is to create a new C++ executable that links statically against the core MLIR libraries, the standard dialect libraries and our custom pass library. This results in a tool that functions exactly like <code class="language-plaintext highlighter-rouge">mlir-opt</code>, but extended to specifically include your pass.</p> <p>Let’s create a new directory for our “Hello World” MLIR pass called <code class="language-plaintext highlighter-rouge">PrintOpsPass</code> which can simply print the names of each operations. If you look at the C++ code for a pass, it can be intimidating. There are templates nested inside templates and macros with names that look like they were shouted by a compiler. But once you strip away the noise, it’s actually quite elegant.</p> <p>Create a file called <code class="language-plaintext highlighter-rouge">my-opt.cpp</code>, and start writing the pass by wrapping everything in an anonymous namespace (<code class="language-plaintext highlighter-rouge">namespace {...}</code>). In C++, this is a trick to make sure our class is only visible inside this specific file. We do this because eventually, we might link dozens of passes together into one tool, and we don’t want out <code class="language-plaintext highlighter-rouge">PrintOpsPass</code> colliding with someone else’s <code class="language-plaintext highlighter-rouge">PrintOpsPass</code>.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">using</span> <span class="k">namespace</span> <span class="n">mlir</span><span class="p">;</span>

<span class="k">namespace</span> <span class="p">{</span>
      <span class="k">struct</span> <span class="nc">PrintOpsPass</span> <span class="o">:</span> <span class="n">PassWrapper</span><span class="o">&lt;</span><span class="n">PrintOpsPass</span><span class="p">,</span> <span class="n">Operation</span><span class="o">&lt;</span><span class="n">ModuleOp</span><span class="o">&gt;&gt;</span> <span class="p">{}</span>
<span class="p">}</span>
</code></pre></div></div> <p>The above code defines our pass but at first glance it looks scary, especially, if you have not used <a href="https://en.wikipedia.org/wiki/Curiously_recurring_template_pattern">CRTP</a>(Curiously Recurring Template Pattern) in C++ before. Let’s look into it to clear away all the noise. We are defining our pass by inheriting from <code class="language-plaintext highlighter-rouge">PassWrapper</code>. This is a helper class MLIR provides to handle all the boilerplate of registering a pass. Also, notice the template arguments: <code class="language-plaintext highlighter-rouge">PrintOpsPass</code> and <code class="language-plaintext highlighter-rouge">OperationPass&lt;ModuleOp&gt;</code>. We are defining struct <code class="language-plaintext highlighter-rouge">PrintOpsPass</code>, but we are passing <code class="language-plaintext highlighter-rouge">PrintOpsPass</code> as a template argument to its own parent! This is known as the <strong>CRTP</strong>.</p> <p>In standard C++ OOP, runtime polymorphism is typically implemented using virtual functions, which introduce indirection via vtable lookups. While this overhead is negligible in most applications, it can be significant in compiler hot paths that execute at scale. Therefore we are passing <code class="language-plaintext highlighter-rouge">PrintOpsPass</code> into <code class="language-plaintext highlighter-rouge">PassWrapper</code> to give the parent class a compile-time pointer to its child. This allows <code class="language-plaintext highlighter-rouge">PassWrapper</code> to implement boilerplate methods (like <code class="language-plaintext highlighter-rouge">clone()</code> or <code class="language-plaintext highlighter-rouge">getId()</code>) for us, specifically customized for our class, without needing a single virtual function call. This is called static polymorphism.</p> <p>The second argument we are passing to the <code class="language-plaintext highlighter-rouge">PassWrapper</code> is called Traits. In MLIR, capabilities are often injected via these template arguments. This specific trait defines the behavioural constraints of your pass. By adding the <code class="language-plaintext highlighter-rouge">OperationPass</code> trait, we are telling the framework; “This pass is designed to run on specific operations.”. Also by specializing it with <code class="language-plaintext highlighter-rouge">&lt;ModuleOp&gt;</code>, we are adding a constraint; “This pass only works on <code class="language-plaintext highlighter-rouge">Module</code> operations.” If you tried to run this pass on a standard function, the compiler (via this trait) would know it’s illegal before the code even runs.</p> <p>Now that we have created the basic class structure, we need to give our pass a unique identity and wire it up so we can actually trigger it from the commandline.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="nc">PrintOpsPass</span> <span class="o">:</span> <span class="n">PassWrapper</span><span class="o">&lt;</span><span class="n">PrintOpsPass</span><span class="p">,</span> <span class="n">OperationPass</span><span class="o">&lt;</span><span class="n">ModuleOp</span><span class="o">&gt;&gt;</span> <span class="p">{</span>
    <span class="c1">// This creates a unique id for the pass</span>
    <span class="n">MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID</span><span class="p">(</span><span class="n">PrintOpsPass</span><span class="p">);</span>

    <span class="n">StringRef</span> <span class="n">getArgument</span><span class="p">()</span> <span class="k">const</span> <span class="k">override</span> <span class="p">{</span> <span class="k">return</span> <span class="s">"print-opt"</span><span class="p">;</span> <span class="p">}</span>
    <span class="n">StringRef</span> <span class="n">getDescription</span><span class="p">()</span> <span class="k">const</span> <span class="k">override</span> <span class="p">{</span> <span class="k">return</span> <span class="s">"This is a pass that will print the operation names. This is a analysis pass."</span><span class="p">;</span> <span class="p">}</span>
<span class="p">};</span>
</code></pre></div></div> <ul> <li><code class="language-plaintext highlighter-rouge">MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID</code>, will inject a static variable into our pass class that will exist at a unique memory address in our program. MLIR then uses that raw memory address as the unique identifier for our pass.</li> <li><code class="language-plaintext highlighter-rouge">getArgument()</code>, hooks our C++ code directly into the compiler’s commandline parser. Later, when we compile out tool, we will be able to trigger this exact C++ class just by typing <code class="language-plaintext highlighter-rouge">./our-custom-mlir-opt --print-opt</code> in the terminal.</li> <li><code class="language-plaintext highlighter-rouge">getDescription()</code>, hooks its string argument automatically into the <code class="language-plaintext highlighter-rouge">--help</code> menu. If someone runs <code class="language-plaintext highlighter-rouge">./out-custom-mlir-opt --help</code>, the MLIR framework will automatically list <code class="language-plaintext highlighter-rouge">--print-opt</code> right next to this description.</li> </ul> <p>Finally, we reach the heart of the pass, the <code class="language-plaintext highlighter-rouge">runOnOperation()</code> method. If the metadata above is how we trigger the pass from the command line, <code class="language-plaintext highlighter-rouge">runOnOperation()</code> is what actually executes when that trigger is pulled.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="nc">PrintOpsPass</span> <span class="o">:</span> <span class="n">PassWrapper</span><span class="o">&lt;</span><span class="n">PrintOpsPass</span><span class="p">,</span> <span class="n">OperationPass</span><span class="o">&lt;</span><span class="n">ModuleOp</span><span class="o">&gt;&gt;</span> <span class="p">{</span>
    <span class="c1">// ... (metadata stuff we just wrote) ...</span>

    <span class="c1">// pass logic</span>
    <span class="kt">void</span> <span class="n">runOnOperation</span><span class="p">()</span> <span class="k">override</span> <span class="p">{</span>
        <span class="c1">// getOperation() returns the top-level ops that this pass is running on (Usually the Module)</span>
        <span class="c1">// .walk() automatically iterates through every nested operation inside it</span>
        <span class="n">getOperation</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">walk</span><span class="p">([](</span><span class="n">Operation</span> <span class="o">*</span><span class="n">op</span><span class="p">){</span>
            <span class="n">llvm</span><span class="o">::</span><span class="n">outs</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="s">"Visiting Op: "</span> <span class="o">&lt;&lt;</span> <span class="n">op</span><span class="o">-&gt;</span><span class="n">getName</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="s">";</span><span class="se">\n</span><span class="s">"</span><span class="p">;</span>
        <span class="p">});</span>
    <span class="p">}</span>
<span class="p">};</span>
</code></pre></div></div> <p>The first thing we do is call <code class="language-plaintext highlighter-rouge">getOperation()</code>. Because we told the framework earlier that this is an <code class="language-plaintext highlighter-rouge">OperationPass&lt;ModulePass&gt;</code>, this call comes with a guarantee that it will return top-level <code class="language-plaintext highlighter-rouge">Module</code> operation that acts as the container for our entire program.</p> <p>Next we need to look at every single operation inside that module. Remember, an MLIR program is structured like a massive tree: Modules contain Functions, Functions contain Blocks, and Blocks contain Operations (which might contain even more Blocks!). For this purpose, MLIR gives us the <code class="language-plaintext highlighter-rouge">.walk()</code> utility. Finally, we do a simple print to grab the operation’s name.</p> <p>Now we have our basic pass, but it’s just a C++ class floating in the coid. To actually run it against our previous <code class="language-plaintext highlighter-rouge">add.mlir</code> file, we need to build an executable.</p> <p>Remember earlier when we talked about building our own custom version of <code class="language-plaintext highlighter-rouge">mlir-opt</code>? We aren’t actually compiling a shared library to plug into an existing tool; we are compiling a brand new, standalone compiler tool from scratch. To do that we need a <code class="language-plaintext highlighter-rouge">main()</code> function. You can put this right at the bottom of the same C++ file.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">"mlir/InitAllDialects.h"</span><span class="cp">
#include</span> <span class="cpf">"mlir/InitAllPasses.h"</span><span class="cp">
#include</span> <span class="cpf">"mlir/Pass/PassManager.h"</span><span class="cp">
#include</span> <span class="cpf">"mlir/Tools/mlir-opt/MlirOptMain.h"</span><span class="cp">
</span>
<span class="k">using</span> <span class="k">namespace</span> <span class="n">mlir</span><span class="p">;</span>
<span class="c1">// ... (our PrintOpsPass struct is up here) ...</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// create a registry and load all standard MLIR dialects</span>
    <span class="n">DialectRegistry</span> <span class="n">registry</span><span class="p">;</span>
    <span class="n">registerAllDialects</span><span class="p">(</span><span class="n">registry</span><span class="p">);</span>

    <span class="c1">// register our custom pass with the command line parser</span>
    <span class="n">PassRegistration</span><span class="o">&lt;</span><span class="n">PrintOpsPass</span><span class="o">&gt;</span><span class="p">();</span>

    <span class="c1">// run the tool (handles command line arguments, parsing, etc.)</span>
    <span class="k">return</span> <span class="n">asMainReturnCode</span><span class="p">(</span>
        <span class="n">MlirOptMain</span><span class="p">(</span><span class="n">argc</span><span class="p">,</span> <span class="n">argv</span><span class="p">,</span> <span class="s">"My Custom MLIR Optimizer"</span><span class="p">,</span> <span class="n">registry</span><span class="p">)</span>
    <span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div> <p>This looks surprisingly short for a custom compiler tool, right? That is the beauty of MLIR’s modular design.</p> <p>When our tool reads the <code class="language-plaintext highlighter-rouge">add.mlir</code> file, it is going to encounter operations like <code class="language-plaintext highlighter-rouge">func.func</code> and <code class="language-plaintext highlighter-rouge">arith.addi</code>. If we don’t explicitly teach our tool what <code class="language-plaintext highlighter-rouge">func</code> and <code class="language-plaintext highlighter-rouge">arith</code> mean, it will throw a parsing error immediately. By creating a <code class="language-plaintext highlighter-rouge">DialectRegistry</code> and calling <code class="language-plaintext highlighter-rouge">registerAllDialects</code>, we are loading the definitions of every standard in-tree MLIR dialect into out tool’s memory.</p> <p>After registering all in-tree dialects, we have to register our custom pass using the <code class="language-plaintext highlighter-rouge">PassRegistration&lt;&gt;()</code>, so that the commandline parser would know to trigger our pass function when user gives <code class="language-plaintext highlighter-rouge">--print-opt</code> flag.</p> <p>Finally, the most important part, <code class="language-plaintext highlighter-rouge">MlirOptMain</code>. We could manually write the code to open a <code class="language-plaintext highlighter-rouge">.mlir</code> file, read the text, parse it into an MLIR module, initilize a Pass Manager, schedule our pass, catch errors and print the output back to terminal. But that would take a hundreds of lines of tedious boilerplate. Instead, MLIR provides <code class="language-plaintext highlighter-rouge">MlirOptMain</code>. We just hand it our commandline arguments (<code class="language-plaintext highlighter-rouge">argc</code>,<code class="language-plaintext highlighter-rouge">argv</code>) and our loaded registry. It takes over, acts exactly like the standard <code class="language-plaintext highlighter-rouge">mlir-opt</code> tool we used earlier, and handles all the file I/O and threading for us automatically.</p> <p>We have our C++ pass, and we have our driver. Now we just need to compile it. If you have spent any time in C++ compiler engineering, you know what time it is: CMake time. I won’t bore you with a deep dive into CMake syntax—our focus is on the IR, not the build system. Assuming you saved all that C++ code we just wrote into a file named <code class="language-plaintext highlighter-rouge">my-opt.cpp</code>, here is the <code class="language-plaintext highlighter-rouge">CMakeLists.txt</code> file you need to tie everything together.</p> <div class="language-cmake highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cmake_minimum_required</span><span class="p">(</span>VERSION 3.13<span class="p">)</span>
<span class="nb">project</span><span class="p">(</span>my-opt<span class="p">)</span>

<span class="nb">find_package</span><span class="p">(</span>MLIR REQUIRED CONFIG<span class="p">)</span>

<span class="nb">list</span><span class="p">(</span>APPEND CMAKE_MODULE_PATH <span class="si">${</span><span class="nv">MLIR_CMAKE_DIR</span><span class="si">}</span><span class="p">)</span>
<span class="nb">list</span><span class="p">(</span>APPEND CMAKE_MODULE_PATH <span class="si">${</span><span class="nv">LLVM_CMAKE_DIR</span><span class="si">}</span><span class="p">)</span>

<span class="nb">include</span><span class="p">(</span>TableGen<span class="p">)</span>
<span class="nb">include</span><span class="p">(</span>AddLLVM<span class="p">)</span>
<span class="nb">include</span><span class="p">(</span>AddMLIR<span class="p">)</span>
<span class="nb">include</span><span class="p">(</span>HandleLLVMOptions<span class="p">)</span>

<span class="nb">include_directories</span><span class="p">(</span><span class="si">${</span><span class="nv">LLVM_INCLUDE_DIR</span><span class="si">}</span><span class="p">)</span>
<span class="nb">include_directories</span><span class="p">(</span><span class="si">${</span><span class="nv">MLIR_INCLUDE_DIR</span><span class="si">}</span><span class="p">)</span>
<span class="nb">link_directories</span><span class="p">(</span><span class="si">${</span><span class="nv">LLVM_LIBRARY_DIR</span><span class="si">}</span><span class="p">)</span>
<span class="nb">add_definitions</span><span class="p">(</span><span class="si">${</span><span class="nv">LLVM_DEFINITIONS</span><span class="si">}</span><span class="p">)</span>

<span class="c1"># Define our executable</span>
<span class="nb">add_executable</span><span class="p">(</span>my-opt my-opt.cpp<span class="p">)</span>

<span class="nf">llvm_update_compile_flags</span><span class="p">(</span>my-opt<span class="p">)</span>

<span class="c1"># Link the necessary MLIR libraries</span>
<span class="c1"># We need MlirOptLib for the main entry point, and the others for IR/Passes.</span>
<span class="nb">target_link_libraries</span><span class="p">(</span>my-opt PRIVATE
  MLIRIR
  MLIRSupport
  MLIRPass
  MLIROptLib    <span class="c1"># contains MlirOptMain</span>
  MLIRRegisterAllDialects    <span class="c1"># contains standard dialects</span>
  MLIRRegisterAllPasses      <span class="c1"># contains standard passes</span>
<span class="p">)</span>
</code></pre></div></div> <p>While we are skipping a line-by-line breakdown, pay attention to the <code class="language-plaintext highlighter-rouge">target_link_libraries</code> at the bottom. This is where the magic happens. We are taking our tiny, custom <code class="language-plaintext highlighter-rouge">my-opt</code> executable and linking it against the massive, pre-compiled MLIR libraries (like <code class="language-plaintext highlighter-rouge">MLIRIR</code> and <code class="language-plaintext highlighter-rouge">MLIROptLib</code>).</p> <p>Once you have this boilerplate working, save it. You can reuse this exact setup later when you graduate from simple analysis passes to building more complex projects.</p> <p>Let’s finally build. Open your terminal in the diretory containing your <code class="language-plaintext highlighter-rouge">my-opt.cpp</code> and <code class="language-plaintext highlighter-rouge">CMakeLists.txt</code>, and run the standard CMake build command (Don’t forget to use the <code class="language-plaintext highlighter-rouge">load-llvm-dev</code> to load the installed LLVM from the previous section):</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir </span>build
<span class="nb">cd </span>build
cmake ..
make
</code></pre></div></div> <p>If everything is linked correctly to your LLVM installation, you should now have a shiny new executable named <code class="language-plaintext highlighter-rouge">my-opt</code> sitting in your build folder. Let’s use our custom tool to compile the <code class="language-plaintext highlighter-rouge">add.mlir</code> from earlier.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./my-opt --print-opt ./add.mlir -o /dev/null
</code></pre></div></div> <p>Because our compiler tool inherits from MLIR’s core infrastructure, it acts exactly like the standard <code class="language-plaintext highlighter-rouge">mlir-opt</code>. By default, it will take the input file, run our pass, and then print the entire resulting MLIR code back to the terminal. Since we only want to see our pass’s analysis log and not a giant wall of MLIR code, we use <code class="language-plaintext highlighter-rouge">-o /dev/null</code> to tell the tool to quietly discard the final IR output.</p> <p>When you run it, your terminal should output exactly what we asked for:</p> <pre><code class="language-txt">Visiting Op: builtin.module;
Visiting Op: func.func;
Visiting Op: arith.addi;
Visiting Op: func.return;
</code></pre> <p><strong>Success!!!</strong></p> <p>Our custom tool successfully parsed the <code class="language-plaintext highlighter-rouge">.mlir</code> file, walked the AST from top-level module all the way down to the individual arithmetic instructions, and execute our custom C++ logic at every node.</p> <h3 id="build-mlir-dialects">Build MLIR Dialects</h3>]]></content><author><name></name></author><category term="notes"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[Start writing with MLIR]]></summary></entry><entry><title type="html">Intro to MLIR</title><link href="https://kabilanma.github.io/blog/2026/MLIR-1/" rel="alternate" type="text/html" title="Intro to MLIR"/><published>2026-02-06T06:01:00+00:00</published><updated>2026-02-06T06:01:00+00:00</updated><id>https://kabilanma.github.io/blog/2026/MLIR-1</id><content type="html" xml:base="https://kabilanma.github.io/blog/2026/MLIR-1/"><![CDATA[<h2 id="introduction">Introduction</h2> <hr/> <p>MLIR is a sub-project within the LLVM ecosystem. Traditionally, LLVM provides the backend infrastructure to execute programs, offering APIs to analyze and optimize the Intermediate Representation (IR) as needed. However, LLVM IR relies on a fixed, low-level instruction set. For language creators, this has historically meant building a frontend to parse an AST and lowering it directly to LLVM IR to leverage existing optimization passes.</p> <p>The challenge arises when developers try to implement domain-specific features. Too often, the compiler community ends up reinventing the wheel, re-implementing similar optimizations and structures repeatedly. MLIR was created to solve this problem, specifically designing tools to increase reusability and extensibility across compiler infrastructure.</p> <p>I recently started my PhD at Virginia Tech and am currently taking a course on LLVM. To be honest, I enrolled because I have almost zero self-discipline to learn it on my own. My true motive isn’t just to learn LLVM, but to master MLIR. However, I realized I needed a solid understanding of the underlying LLVM infrastructure to effectively build projects in MLIR. I’m taking the Compiler Optimization course by <a href="https://binoyravindran.github.io/">Prof. Binoy Ravindran</a> in Spring 2026. Since the course started, I’ve been trying to learn MLIR in parallel. The problem? Every tutorial out there focuses heavily on architecture design and high-level decisions, rather than showing me how to actually build something with MLIR.</p> <p>I come from the “YouTube generation” of programmers. I learn best when someone shows me the absolute minimal code to get something running, and then we figure out the rest later. My philosophy is: First build, then ask questions. I’m writing this blog series to document my journey starting with MLIR with minimal prior knowledge. I hope that by recording my “build-first” approach, others who are struggling with the steep learning curve might gain something from it, too.</p> <h3 id="installing-llvm--mlir-the-hard-way-is-the-easy-way">Installing LLVM &amp; MLIR (The Hard Way is the Easy Way)</h3> <p>First things first: we need to install LLVM and MLIR. While you can sometimes find binaries, the only “real” way to work with MLIR—which changes almost daily—is to build from source.</p> <ol> <li> <p><strong>Install System Dependencies</strong> Before we even touch LLVM code.</p> <p>Fedora</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="nb">sudo </span>dnf <span class="nb">install </span>git cmake ninja-build gcc-c++ python3-devel libomp-devel
</code></pre></div> </div> <p>Debian/Ubuntu:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="nb">sudo </span>apt-get update
   <span class="nb">sudo </span>apt-get <span class="nb">install </span>git cmake ninja-build build-essential python3-dev libomp-dev
</code></pre></div> </div> </li> <li><strong>Clone the Source</strong>. I use <code class="language-plaintext highlighter-rouge">--depth 1</code> to avoid downloading the entire commit history, which saves a massive amount of time and disk space. <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   git clone <span class="nt">--depth</span> 1 https://github.com/llvm/llvm-project.git
</code></pre></div> </div> </li> <li> <p><strong>Configure and Build</strong>. Create a directory where we will eventually install the binaries, and then set up the build.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="nb">mkdir</span> ~/llvm-dev

   <span class="nb">cd </span>llvm-project
   <span class="nb">mkdir </span>build <span class="o">&amp;&amp;</span> <span class="nb">cd </span>build

   cmake <span class="nt">-G</span> Ninja <span class="nt">-S</span> ../llvm <span class="nt">-B</span> <span class="nb">.</span> <span class="se">\</span>
       <span class="nt">-DLLVM_ENABLE_PROJECTS</span><span class="o">=</span><span class="s2">"mlir;clang;openmp;lld"</span> <span class="se">\</span>
       <span class="nt">-DLLVM_TARGETS_TO_BUILD</span><span class="o">=</span><span class="s2">"Host;NVPTX;AMDGPU"</span> <span class="se">\</span>
       <span class="nt">-DCMAKE_BUILD_TYPE</span><span class="o">=</span>Release <span class="se">\</span>
       <span class="nt">-DLLVM_ENABLE_ASSERTIONS</span><span class="o">=</span>ON <span class="se">\</span>
       <span class="nt">-DCMAKE_INSTALL_PREFIX</span><span class="o">=</span><span class="nv">$HOME</span>/llvm-dev <span class="se">\</span>
       <span class="nt">-DLLVM_PARALLEL_LINK_JOBS</span><span class="o">=</span>1
</code></pre></div> </div> </li> <li> <p><strong>Build and Install</strong>. Time to compile now! Adjust <code class="language-plaintext highlighter-rouge">-j16</code> based on your CPU cores. I have 20 cores, but I strictly use 16 to leave some breathing room for the OS and my ever running youtube.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   <span class="c"># This will take 30-60 minutes depending on your machine.</span>
   ninja <span class="nt">-j16</span>
      
   <span class="c"># Install the binaries to ~/llvm-dev directory.</span>
   ninja <span class="nb">install</span>
</code></pre></div> </div> </li> <li> <p><strong>Final Step</strong> (Environment Management).</p> <p>I have a stable LLVM installed globally for all my assignment purposes, therefore instead of permanently polluting my global PATH (which can break other builds), I prefer to load the environment only when I actually need it. This keeps my system clean and makes it easier to switch between different LLVM versions later. Add the following alias to your <code class="language-plaintext highlighter-rouge">.bashrc</code>:</p> <ol> <li> <p>Open the shell configuration file (<code class="language-plaintext highlighter-rouge">.bashrc</code> by default in most Linux distros).</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> nano ~/.bashrc
</code></pre></div> </div> </li> <li>Scroll to the very end of the file and add this line: <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nb">alias </span>load-llvm-dev<span class="o">=</span><span class="s1">'export PATH="$HOME/llvm-dev/bin:$PATH" &amp;&amp; echo "Dev LLVM Loaded"'</span>
</code></pre></div> </div> </li> <li>Save and exit (<code class="language-plaintext highlighter-rouge">Ctrl+O</code>, <code class="language-plaintext highlighter-rouge">Enter</code>, then <code class="language-plaintext highlighter-rouge">Ctrl+X</code>).</li> <li>Reload the configuration so the changes take effect immediately. <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nb">source</span> ~/.bashrc
</code></pre></div> </div> </li> </ol> <p>Now, whenever you open a fresh terminal to work on this project, just type:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>   load-llvm-dev
</code></pre></div> </div> <p>And I am ready to go for that session.</p> </li> </ol> <p><strong>Verify the Installation</strong></p> <p>Building LLVM takes a long time, and a lot can go wrong. Before we move on, let’s confirm that out shell can actually find the tools and that they run.</p> <p>First, load your environment:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>load-llvm-dev
</code></pre></div></div> <p>Now check if <code class="language-plaintext highlighter-rouge">mlir-opt</code> is available:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlir-opt <span class="nt">--version</span>
</code></pre></div></div> <p>If you see something like <code class="language-plaintext highlighter-rouge">LLVM version ... Optimized build...</code>, you are in business.</p> <p>Just seeing the version isn’t enough. As usual in any programming language or framework, let’s write our first “Hello World” in MLIR.</p> <p>First create a file named <code class="language-plaintext highlighter-rouge">hello.mlir</code> with the absolute bare minimum valid MLIR code:</p> <pre><code class="language-mlir">module {
  func.func @main() {
    return
  }
}
</code></pre> <p>Now run ti through the optimizer:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlir-opt hello.mlir
</code></pre></div></div> <p>If it prints the exact same code block to your terminal, congratulations! You have successfully built LLVM and parsed your first piece of MLIR. You are now officially just one step behind me.</p> <p>I plan to use the rest of this post to explain the architectural design of MLIR—mostly for the sake of completeness, as every other resource seems to do. But I believe in learning by doing. So, if you prefer, jump ahead to the next post to start coding. You can treat this section as a reference to come back to once you’ve gotten your hands dirty.</p> <hr/>]]></content><author><name></name></author><category term="notes"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[Information needed to create a setup for MLIR and LLVM.]]></summary></entry><entry><title type="html">Compilers</title><link href="https://kabilanma.github.io/blog/2025/compiler/" rel="alternate" type="text/html" title="Compilers"/><published>2025-04-10T06:01:00+00:00</published><updated>2025-04-10T06:01:00+00:00</updated><id>https://kabilanma.github.io/blog/2025/compiler</id><content type="html" xml:base="https://kabilanma.github.io/blog/2025/compiler/"><![CDATA[<h2 id="introduction">Introduction</h2> <hr/> <p>Compilers are human-machine translators that transform human-readable code into machine-readable programs. Compilers are like our intelligent friend who speaks multiple languages and helps us get around in a foreign country. You don’t need to learn the foreign language to explore the city, you only need to develop the skills to communicate properly with your intelligent friend and make him do whatever you want (not intended in a manipulative way! maybe just a little). We’ve spent around 70 years developing the perfect compiler, and we still haven’t reached a mature stage, because there’s no perfect way to communicate with your friend in all scenarios.</p> <p>I’m personally an introverted person, which means it has always been very difficult for me to make new friends. I still have friends who have been with me for more than 15 years. Now, I’ve decided to learn how to make new friends, and the first step is to develop my communication skills. As the first part of that journey, I’m going to learn how to talk to a computer, just like any nerdy, introverted person would do. No, it’s not about LLMs, because I don’t want to learn English to speak with a Chinese person. I’m going to build a compiler while learning about its intricate parts and technical details.</p> <p>What a weird way to start a project! I’m going to use this as an entry for record-keeping.</p> <hr/> <h4 id="things-i-should-know">Things I should know</h4> <ol> <li>How to take all the English letters, numbers, and symbols—and make sense of them.</li> <li>How to map what each letter, number, or symbol means—and how to even understand what counts as a number versus an English character.</li> <li>What machine code is, and what it looks like.</li> <li>How to turn all of my program code into machine code.</li> <li>How the compiler knows that I’ve made a mistake in the program before converting it into machine code.</li> </ol> <p>So, what do I know as I start this record? <strong>Nothing!</strong> Just a few tiny details about compilers, thanks to my experience using different compilers for C/C++ projects. What an idiot I am! I’ve been using compilers for so long without even making an effort to understand how they work.</p> <hr/> <h4 id="where-do-i-start">Where do I start</h4> <p>The main part of learning is asking the right questions and knowing what you don’t know. So my first question is: <em>How do we take all the English letters, numbers, and symbols—and make sense of them?</em></p> <p>It’s just like learning a new language. You always start with grammar. So I’m also going to start with the concept of grammar and how it helps answer Question 1.</p> <h2 id="grammar">Grammar</h2> <p>Grammar is the set of rules that define how words are arranged to form meaningful sentences in a language. Its purpose is to ensure clear and consistent communication by organizing words in a structured, understandable way. Therefore, to build any programming language that compilers can understand, we first have to define its grammar. Again, a question arises: What does grammar look like? Does it have verbs or subjects, like in natural languages? To understand this, we need to formally define what a formal grammar looks like in the context of a programming language.</p> <p>I remember studying something like this during my undergraduate Theory of Computation class. It’s time to refresh that memory.</p> <blockquote> <p>A formal grammar is a mathematical specification of a language’s syntax, typically defined as a 4‑tuple <strong>G=(N,Σ,P,S)</strong> where <strong>N</strong> is a finite set of nonterminal symbols, <strong>Σ</strong> a set of terminal symbols (disjoint from <strong>N</strong>), <strong>P</strong> a set of production rules, and <strong>S ∈ N</strong> the start symbol</p> </blockquote> <p>Oh! That’s a lot to digest. I don’t even know what this means at this point. Let’s break it down, part by part, and understand all the small details to fully grasp what it really means.</p> <ol> <li> <em>A formal grammar is a mathematical specification of a language’s syntax</em><br/> Syntax refers to the specific rules that dictate the structure and arrangement of symbols and words in a programming language. Therefore, mathematically specifying this syntax is what is defined as a formal grammar. <br/><br/> </li> <li> <em>typically defined as a 4‑tuple <strong>G=(N,Σ,P,S)</strong></em><br/> Grammar is formally defined as a tuple of four elements, each specifying a set of features/rules of a programming language. <br/><br/> </li> <li> <em><strong>N</strong> is a finite set of nonterminal symbols</em>.<br/> There are a lot of things in this small sentence. Let's break it down. First, <em>what are non-terminal symbols?</em>, <em>what other symbols are there?</em>, <em>why does it have to be finite?</em> and <em>what does finite mean?</em> <br/><br/> <ol> <li> <em>what are non-terminal symbols?, what other symbols are there?</em> <br/>When writing grammar rules, we use two types of symbols: <strong>non-terminal symbols</strong> and <strong>terminal symbols</strong>. <strong>Terminal symbols</strong> are the actual characters or tokens that appear in your program and cannot be broken down any further.<br/><br/> A few examples of non-terminal symbols in a Python-like programming language are:<br/> <pre><code>if, else, print, (, ), +, -, identifier, number</code></pre> <strong>Non-terminal Symbols</strong> are placeholders for patterns or structures made up of terminals or other non-terminals.<br/> <pre><code>print(3+5)</code></pre> Let’s take the above as a simple program written in our own programming language. Now, let’s see how the terminals and non-terminals would make up the grammar.<br/> <pre><code>Program    --&gt; Statement<br />Statement  --&gt; "print" "(" Expression ")"<br />Expression --&gt; Term "+" Term<br />Term       --&gt; number</code></pre> Here, our Program is <code>print(3+5)</code>, which is a non-terminal symbol. According to our grammar, it is made up of terminal symbols such as <code>print</code>, <code>(</code>, and <code>)</code>, and a non-terminal symbol called <code>Expression</code>. The <code>Expression</code> here represents <code>3+5</code>, which is itself a combination of the terminal symbol <code>+</code> and non-terminal symbols like <code>Term</code>. <code>Term</code> is a non-terminal symbol that ultimately represents a terminal symbol, <code>number</code>. Refer the image below for better clarity.<br/> <p style="text-align: center;"> <img src="/assets/img/compiler/terminal-non-terminal.png" alt="Terminal AND Non-terminal" style="max-width: 100%; border-radius: 8px;"/> </p> <br/> Each statement in the grammer above is also known as <strong>Production</strong> and these statements are also know as <strong>Production Rules</strong> We will look into this later. </li> <li><em>why does it have to be finite?</em><br/> Computers (and compilers) are finite machines. They can only hold and process finite amounts of data. If we have infinite number of non-terminals<br/> </li> </ol> </li> <li><em><strong>Σ</strong> a set of terminal symbols (disjoint from N)</em><br/> We’ve already understood what terminal symbols are, but what does <em>disjoint from NM</em> mean? N is the set of non-terminal symbols, as we’ve seen before, and the set of terminal symbols Σ cannot contain any elements from N. This implies that N and Σ are disjoint sets, they have no elements in common. </li> <li><em><strong>P</strong> a set of production rules</em><br/> A <strong>production</strong> (also called a production rule) is a single rule within the grammar that tells how a non-terminal can be replaced (or "expanded") into a sequence of terminals and/or other non-terminals. We have already looked at an example of a set of productions. Consider the earlier example: <code>print(3+5)</code>. We can define a production rule to read the program as follows: <pre><code>Program    --&gt; Statement<br />Statement  --&gt; "print" "(" Expression ")"<br />Expression --&gt; Term "+" Term<br />Term       --&gt; number</code></pre> These are what we call <strong>production rules</strong>. </li> <li><em><strong>S ∈ N</strong> the start symbol</em><br/> <strong>S</strong> is one of the important specification which indicates the starting point of any scan operations. Also <strong>S</strong> should belong to N (set of non-terminal symbols), which implies that <strong>S</strong> is a subset of <strong>N</strong> </li><br/> Wow! Just one simple sentence carried this much weight?! </ol> <p>All of this looks very complicated. Do we really need to build all of it just to perform a simple task that might not even require everything? <br/> <strong>NO!</strong></p>]]></content><author><name></name></author><category term="notes"/><category term="formatting"/><category term="code"/><category term="toc"/><category term="incomplete"/><summary type="html"><![CDATA[A Record Keeping of Compiler Learning Materials]]></summary></entry><entry><title type="html">From Atheist to Believer</title><link href="https://kabilanma.github.io/blog/2025/ghost-story/" rel="alternate" type="text/html" title="From Atheist to Believer"/><published>2025-02-17T06:01:00+00:00</published><updated>2025-02-17T06:01:00+00:00</updated><id>https://kabilanma.github.io/blog/2025/ghost-story</id><content type="html" xml:base="https://kabilanma.github.io/blog/2025/ghost-story/"><![CDATA[<h4 id="this-is-a-story-happened-in-my-personal-life-which-changed-my-perspective">This is a Story Happened in My Personal Life Which Changed My Perspective</h4> <hr/> <p>I was a staunch atheist. Science and logic were my guiding principles, and I never believed in anything supernatural. That was until one strange experience changed my entire outlook on life.</p> <p>During the COVID-19 lockdown in 2021, I had a routine with four close friends. Every evening, we would gather, chat about anything and everything, sometimes gossip, and then go for dinner. Our meeting spot was always the same—one of my friends’ houses, conveniently located in the center of town. This friend had a habit of exaggerating stories, so we didn’t always take his words seriously.</p> <p>One day, he told us that someone was throwing stones at his house from different directions. The stones were unusual, not the kind found in the nearby area. He suspected that people were trying to scare his family into leaving their home. At first, we brushed it off as another one of his exaggerated tales. But he kept repeating the story every time we met. The more he insisted, the less we paid attention.</p> <p>Then, one evening, we met outside his house before heading to another friend’s place for a funeral. But something was different that day—his entire family was sitting outside, looking tense. When I asked what was happening, my friend told me that, for the past few days, stones had been appearing inside their fully closed house. They had locked all doors and windows, yet the stones still managed to get in. His family had collected a large bag full of these mysterious stones.</p> <p>Curious but skeptical, I asked to go inside the house and see for myself. My other friends refused, saying they had heard strange noises from the kitchen earlier. Still, I went in with my friend. He locked all the doors and windows, making sure there was no way for anyone to throw anything from outside. Then, he called out loudly, as if inviting something to reveal itself. I found this amusing and couldn’t help but laugh. It reminded me of ghost-hunting shows from my childhood. Nothing happened at first, and I was about to dismiss the whole thing when, suddenly, a stone landed on a metal plate on the dining table.</p> <p>There was no one else in the house. No hidden places. No logical explanation. Yet, a stone had appeared from nowhere.</p> <p>Still determined to find an answer, I stayed quiet about what I had seen. Later, two men from a nearby workshop came by, curious about the rumors. My friend invited them in, and I joined them. This time, as my friend repeated his ritual, something happened that I will never forget.</p> <p>I saw a stone appear in mid-air—just a few feet in front of me. It wasn’t there one moment, and the next, it materialized out of thin air before being thrown across the room, hitting a wall.</p> <p>I ran outside, terrified. I told my friends what I had seen, and we discussed it at length, but I couldn’t explain it. Later that night, at the funeral house, another friend shared similar eerie experiences from his shop in the same town. Normally, I would have dismissed such stories, but now, I couldn’t.</p> <p>A few days later, when we met again, my friend’s family was back inside their home. I asked what had changed. He told me that a temple priest had visited their house, performed a ritual, and lit a candle, asking them to let it burn for a day. After that, the disturbances stopped completely.</p> <p>This experience shook me to the core. It made me realize that there are things in this world beyond human understanding. We perceive only a tiny fraction of reality, and there is so much more that we might never comprehend.</p> <p>Since then, I no longer dismiss the unknow so easily. For a fact, I know that there are things out there our mind and reality cannot easily accept and I am ready to accept it and walk with a newfound respect for the mysteries of life.</p>]]></content><author><name></name></author><category term="story"/><category term="formatting"/><summary type="html"><![CDATA[This is a Story Happened in My Personal Life Which Changed My Perspective]]></summary></entry><entry><title type="html">GNU Debugger (GDB) Quick Notes</title><link href="https://kabilanma.github.io/blog/2025/gdb/" rel="alternate" type="text/html" title="GNU Debugger (GDB) Quick Notes"/><published>2025-01-21T06:01:00+00:00</published><updated>2025-01-21T06:01:00+00:00</updated><id>https://kabilanma.github.io/blog/2025/gdb</id><content type="html" xml:base="https://kabilanma.github.io/blog/2025/gdb/"><![CDATA[<p><strong>GDB</strong> (<strong>G</strong>NU <strong>D</strong>e<strong>B</strong>ugger) is a powerful commandline debugging tool for programs written in C, C++, and other languages, allowing developers to run programs step-by-step, set breakpoints, inspect variables, view the call stack, and modify program behavior during execution to identify and fix bugs efficiently.</p> <hr/> <p>First install GDB:</p> <p><code class="language-plaintext highlighter-rouge">sudo apt install gdb</code></p> <p>Consider this code snippet:</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
</span>
<span class="kt">int</span> <span class="nf">main</span><span class="p">()</span>
<span class="p">{</span>
    <span class="kt">long</span> <span class="kt">double</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">step</span><span class="p">;</span>

    <span class="n">printf</span><span class="p">(</span><span class="s">"Enter the start value: "</span><span class="p">);</span>
    <span class="n">scanf</span><span class="p">(</span><span class="s">"%Lf"</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">start</span><span class="p">);</span>

    <span class="n">printf</span><span class="p">(</span><span class="s">"Enter the end value: "</span><span class="p">);</span>
    <span class="n">scanf</span><span class="p">(</span><span class="s">"%Lf"</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">end</span><span class="p">);</span>

    <span class="n">printf</span><span class="p">(</span><span class="s">"Enter the step value: "</span><span class="p">);</span>
    <span class="n">scanf</span><span class="p">(</span><span class="s">"%Lf"</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">step</span><span class="p">);</span>

    <span class="k">while</span> <span class="p">(</span><span class="n">start</span> <span class="o">!=</span> <span class="n">end</span><span class="p">)</span>
    <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"Value: %Lf</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">start</span><span class="p">);</span>
        <span class="n">start</span> <span class="o">+=</span> <span class="n">step</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>Compile the program with <code class="language-plaintext highlighter-rouge">gcc main.c -o main.out</code> , and run with <code class="language-plaintext highlighter-rouge">./main.out</code>.</p> <p>When we run the program with the following output:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Enter the start value: 1
Enter the end value: 5
Enter the step value: 0.2
</code></pre></div></div> <p>The program will not end because of the floating point error. We can use the GDB debugger to find the root cause of the problem.</p> <p>To do this, we can compile the program using gcc with the information needed for debugging, which includes the mapping between the source code and the binary. Because of this extra information, this compiled binary will be larger than the normal binary file.</p> <p>To compile:</p> <p><code class="language-plaintext highlighter-rouge">gcc main.c -o main.out -g</code></p> <p>Flag <code class="language-plaintext highlighter-rouge">-g</code> helps to compile with debugging information.</p> <p>To invoke the GDB with the binary file:</p> <p><code class="language-plaintext highlighter-rouge">gdb main.out</code></p> <p>This will open-up the GDB commandline debugger. The commands below that starts with <code class="language-plaintext highlighter-rouge">(gdb)</code> are commands entered in the commandline debugger.</p> <p>We can see the source-code using the command <code class="language-plaintext highlighter-rouge">(gdb) list</code> . This will print the entire source code mapped in the main.out. In some cases this can also help to find the line number of the source code to set the break-points later.</p> <p>Use the command, <code class="language-plaintext highlighter-rouge">(gdb) break 17</code> to create a breakpoint on the line number 16 (In our example case, just after where the <code class="language-plaintext highlighter-rouge">while</code> loops begins).</p> <p>The command <code class="language-plaintext highlighter-rouge">(gdb) deassemble main</code> will print the assembly code of the main function (not the entire program in the main.c file).</p> <p>The command <code class="language-plaintext highlighter-rouge">(gdb) run</code> now runs the program and break at the set breakpoint and let us analyse the memory and individual variables.</p> <p><code class="language-plaintext highlighter-rouge">(gdb) print &lt;variable&gt;</code> will print the value of the variable in the breakpoint. For example, in our case, <code class="language-plaintext highlighter-rouge">(gdb) print start</code> will print the start value in the while loop and we can use <code class="language-plaintext highlighter-rouge">(gdb) continue</code> to continue the program until it meets the next breakpoint. We can pause and see the value of the variable <code class="language-plaintext highlighter-rouge">start</code> when it is supposed to have 5 but you can see it is actually not 5 but 4.99999999999999999957 which makes the while loop condition to be true all the time and the loop continue infinitely. This concluded the loss of precission error in floating point numbers is in the program.</p> <p>There are few other useful GDB command below:</p> <ol> <li> <p><code class="language-plaintext highlighter-rouge">run arg1 arg2 ....</code> : We can run the program using this command and also pass any number of optional arguments that the program might require.</p> </li> <li><code class="language-plaintext highlighter-rouge">quit</code> : Quit the debugger.</li> <li><code class="language-plaintext highlighter-rouge">break</code> : Set breaking points in the program <ol> <li><code class="language-plaintext highlighter-rouge">break main</code> : Create a breaking point at the start of the main function.</li> <li><code class="language-plaintext highlighter-rouge">break 42</code> : Create a breaking point at the line number 42.</li> <li><code class="language-plaintext highlighter-rouge">break file.c:15</code> : Create a breaking point at line 15 of file.c</li> </ol> </li> <li><code class="language-plaintext highlighter-rouge">info breakpoints</code> : Get the details about the points set in the program.</li> <li><code class="language-plaintext highlighter-rouge">delete 2</code> : Delete the 2nd breaking point (breaking point number can be retrived from <code class="language-plaintext highlighter-rouge">info</code> command)</li> <li><code class="language-plaintext highlighter-rouge">watch var</code> : Watch a variable and stop when its value changes.</li> <li><code class="language-plaintext highlighter-rouge">continue</code> ****(or <code class="language-plaintext highlighter-rouge">c</code>): Continue execution until the next breakpoint or end.</li> <li><code class="language-plaintext highlighter-rouge">step</code> (or <code class="language-plaintext highlighter-rouge">s</code>): Step into a function call.</li> <li><code class="language-plaintext highlighter-rouge">next</code> (or <code class="language-plaintext highlighter-rouge">n</code>): Step over a function call.</li> <li><code class="language-plaintext highlighter-rouge">finish</code>: Run until the current function returns.</li> <li><code class="language-plaintext highlighter-rouge">until 50</code>: Run until line number 50.</li> <li><code class="language-plaintext highlighter-rouge">print x</code> : Print the value of a variable.</li> <li><code class="language-plaintext highlighter-rouge">display x</code> : Automatically print a variable’s value every time it changes.</li> <li><code class="language-plaintext highlighter-rouge">info locals</code>: Show local variables in the current stack frame.</li> <li><code class="language-plaintext highlighter-rouge">info args</code>: Show function arguments in the current stack frame.</li> <li><code class="language-plaintext highlighter-rouge">backtrace</code> (or <code class="language-plaintext highlighter-rouge">bt</code>): Show the call stack.</li> <li><code class="language-plaintext highlighter-rouge">frame 2</code> (or <code class="language-plaintext highlighter-rouge">f</code>): Move to a specific stack frame.</li> <li><code class="language-plaintext highlighter-rouge">list</code> (or <code class="language-plaintext highlighter-rouge">l</code>): Show source code near the current execution point.</li> <li><code class="language-plaintext highlighter-rouge">list</code></li> <li><code class="language-plaintext highlighter-rouge">list 10</code> : List around line 10</li> <li><code class="language-plaintext highlighter-rouge">list main</code> : List the main function</li> <li><code class="language-plaintext highlighter-rouge">condition</code>: Set a condition on a breakpoint.</li> <li><code class="language-plaintext highlighter-rouge">condition 2 x &gt; 5</code> : Set a breakpoint number 2 only when variable value x is greater than 5</li> <li><code class="language-plaintext highlighter-rouge">set var x = 42</code> : Modify a variable or memory.</li> </ol>]]></content><author><name></name></author><category term="notes"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[This contains the basic informations about using GNU debugger for C/C++ programs.]]></summary></entry><entry><title type="html">An Image Gallery of Chongqing, China</title><link href="https://kabilanma.github.io/blog/2024/apsec2024/" rel="alternate" type="text/html" title="An Image Gallery of Chongqing, China"/><published>2024-12-15T21:01:00+00:00</published><updated>2024-12-15T21:01:00+00:00</updated><id>https://kabilanma.github.io/blog/2024/apsec2024</id><content type="html" xml:base="https://kabilanma.github.io/blog/2024/apsec2024/"><![CDATA[<p>31<sup>st</sup> Asia-Pacific Software Engineering Conference held in <strong>Chongqing, China</strong>. Here are some pictures I captured around the city of Chongqing and the conference.</p> <hr/> <p><strong>Hongya Dong</strong></p> <p>is a an 11-story stilt-building complex in the main commercial district of Jiefangbei in the city of Chongqing, China. It comprises a series of structures built into the hillside along the southern bank of the Jialing River, and is one of the most popular tourist attractions in the city. Across the Jialing River opposite to the Hongya Dong gives better view of the complex along with the Twin bridge over the river.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/apsec_2024/4.jpeg" sizes="95vw"/> <img src="/assets/img/apsec_2024/4.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/apsec_2024/5.jpeg" sizes="95vw"/> <img src="/assets/img/apsec_2024/5.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/apsec_2024/6.jpeg" sizes="95vw"/> <img src="/assets/img/apsec_2024/6.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/apsec_2024/7.jpeg" sizes="95vw"/> <img src="/assets/img/apsec_2024/7.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/apsec_2024/8.jpeg" sizes="95vw"/> <img src="/assets/img/apsec_2024/8.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/apsec_2024/9.jpeg" sizes="95vw"/> <img src="/assets/img/apsec_2024/9.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/apsec_2024/10.jpeg" sizes="95vw"/> <img src="/assets/img/apsec_2024/10.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/apsec_2024/11.jpeg" sizes="95vw"/> <img src="/assets/img/apsec_2024/11.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/apsec_2024/12.jpeg" sizes="95vw"/> <img src="/assets/img/apsec_2024/12.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <hr/> <p><strong>Liziba Station</strong></p> <p>is a monorail station on Line 2 of Chongqing Rail Transit where the station is located on the 19th floor of a residential building which was built along with the station in 2005 where the train goes through the building.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/apsec_2024/21.jpeg" sizes="95vw"/> <img src="/assets/img/apsec_2024/21.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/apsec_2024/22.jpeg" sizes="95vw"/> <img src="/assets/img/apsec_2024/22.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/apsec_2024/23.jpeg" sizes="95vw"/> <img src="/assets/img/apsec_2024/23.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <hr/> <p><strong>Kuixinglou Square</strong></p> <p>is a public square which looks normal ground floor until you take the look one edge of the square which shows that you are in 22nd floor while the opposite edge has public roads on the same floor and it is considered ground floor. Chongqing is a mountainous terrain cyberpunk city.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/apsec_2024/24.jpeg" sizes="95vw"/> <img src="/assets/img/apsec_2024/24.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/apsec_2024/25.jpeg" sizes="95vw"/> <img src="/assets/img/apsec_2024/25.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/apsec_2024/26.jpeg" sizes="95vw"/> <img src="/assets/img/apsec_2024/26.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <hr/> <p><strong>Liberation Monument</strong></p> <p>in Chongqing is the War Victory Monument and People’s Liberation Monument. It is located in the heart of the central business district of Jiefangbei in Yuzhong District, Chongqing. The Jiefangbei clock tower on the monument is one of Chongqing’s most iconic locations. The tower was built in remembrance of China’s victory in the Sino-Japanese war. An interesting fact, at about 28 meters tall, only a few decades ago, the liberation monument was one of the tallest buildings in all of Chongqing. The monument is located in the middle of what is the modern-day pedestrian street and the 4 main roads converge at the monument.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/apsec_2024/27.jpeg" sizes="95vw"/> <img src="/assets/img/apsec_2024/27.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/apsec_2024/28.jpeg" sizes="95vw"/> <img src="/assets/img/apsec_2024/28.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/apsec_2024/29.jpeg" sizes="95vw"/> <img src="/assets/img/apsec_2024/29.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <hr/> <p><strong>Ronghui Hot Springs</strong></p> <p>is where the Asia-Pacific Software Engineering Conference (2024) took place. It is vibrant, friendly and remote location in Chongqing.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/apsec_2024/31.jpeg" sizes="95vw"/> <img src="/assets/img/apsec_2024/31.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/apsec_2024/32.jpeg" sizes="95vw"/> <img src="/assets/img/apsec_2024/32.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/apsec_2024/33.jpeg" sizes="95vw"/> <img src="/assets/img/apsec_2024/33.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/apsec_2024/34.jpeg" sizes="95vw"/> <img src="/assets/img/apsec_2024/34.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/apsec_2024/35.jpeg" sizes="95vw"/> <img src="/assets/img/apsec_2024/35.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div>]]></content><author><name></name></author><category term="conference"/><category term="images"/><summary type="html"><![CDATA[This is about my visit to Chongqing for APSEC 2024 conference.]]></summary></entry></feed>