<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Hello World in MLIR | Kabilan Mahathevan </title> <meta name="author" content="Kabilan Mahathevan"> <meta name="description" content="Start writing with MLIR"> <meta name="keywords" content="academic-website, portfolio-website, kabilan, mahathevan"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/signature.png?8f6f49409677a4094fb4e624daa9f78a"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kabilanma.github.io/blog/2026/MLIR-2/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="//"> <span class="font-weight-bold">Kabilan</span> Mahathevan </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blogs </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Hello World in MLIR</h1> <p class="post-meta"> Created in February 13, 2026 </p> <p class="post-tags"> <a href="//blog/2026"> <i class="fa-solid fa-calendar fa-sm"></i> 2026 </a>   ·   <a href="//blog/tag/formatting"> <i class="fa-solid fa-hashtag fa-sm"></i> formatting</a>   <a href="//blog/tag/code"> <i class="fa-solid fa-hashtag fa-sm"></i> code</a>   ·   <a href="//blog/category/notes"> <i class="fa-solid fa-tag fa-sm"></i> notes</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="introduction">Introduction</h2> <hr> <p>MLIR is not a programming language like C++ or Python; it is a compiler infrastructure—a framework of tools rather than a single tool. Because of this, there is no single “Hello World” program. As I’ve been learning, I’ve realized there are actually three different ways to use this framework, and you need to understand all of them.</p> <ol> <li>Write MLIR program directly using existing dialects.</li> <li>Create a MLIR pass for either optimization of analysis.</li> <li>Build our own dialects by extending the language itself by defining new operations and types.</li> </ol> <p>To really understand how MLIR works, I’m going to walk through a minimal “Hello World” for all three scenarios.</p> <h3 id="write-mlir-program">Write MLIR Program</h3> <p>The MLIR distribution includes a rich set of in-tree dialects, most of which target high-performance tensor compilers and hardware-specific code generation. However, before we tackle those, we need to understand the basics of the IR itself. We will start by manually writing a program using two core dialects: <code class="language-plaintext highlighter-rouge">func</code> (for function abstraction) and <code class="language-plaintext highlighter-rouge">arith</code> (for basic arithmetic operations). This will allow us to see how MLIR represents logic and how the infrastructure processes it without getting bogged down in complex types.</p> <p>Our goal is to get from high-level abstractions down to executable code. To do that, we’ll take a high-level MLIR program (using <code class="language-plaintext highlighter-rouge">func</code> and <code class="language-plaintext highlighter-rouge">arith</code>), lower it into MLIR’s LLVM Dialect, which is basically a 1:1 mapping of LLVM instructions inside MLIR, and finally translate that into pure LLVM IR (<code class="language-plaintext highlighter-rouge">.ll</code>) so the machine can actually run it. Our MLIR program should define a function which takes two integer (<code class="language-plaintext highlighter-rouge">i32</code>) arguments and add them together and return the results.</p> <p>In MLIR, everything is an operation. Operations are the core unit of abstraction and computation, similar in many ways to LLVM instructions. Even defining a function is an operation! The <code class="language-plaintext highlighter-rouge">func</code> dialect has an operation called <code class="language-plaintext highlighter-rouge">func</code> to define functions. We use the <code class="language-plaintext highlighter-rouge">@</code> sigil for global symbols (like function names) and the <code class="language-plaintext highlighter-rouge">%</code> sigil for local values (variables).</p> <div class="language-llvm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">func</span><span class="p">.</span><span class="err">func</span> <span class="vg">@add</span><span class="p">(</span><span class="nv">%arg0</span><span class="err">:</span> <span class="kt">i32</span><span class="p">,</span> <span class="nv">%arg1</span><span class="err">:</span> <span class="kt">i32</span><span class="p">)</span> <span class="err">-</span><span class="p">&gt;</span> <span class="kt">i32</span> <span class="p">{</span>
</code></pre></div></div> <p>This tells the compiler that we are defining a function called <code class="language-plaintext highlighter-rouge">@add</code> which takes two <code class="language-plaintext highlighter-rouge">i32</code> arguments <code class="language-plaintext highlighter-rouge">%arg0</code> and <code class="language-plaintext highlighter-rouge">%arg1</code> and returns a <code class="language-plaintext highlighter-rouge">i32</code> value.</p> <p>Now let’s take a look at the logic inside the block.</p> <div class="language-llvm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">func</span><span class="p">.</span><span class="err">func</span> <span class="vg">@add</span><span class="p">(</span><span class="nv">%arg0</span><span class="err">:</span> <span class="kt">i32</span><span class="p">,</span> <span class="nv">%arg1</span><span class="err">:</span> <span class="kt">i32</span><span class="p">)</span> <span class="err">-</span><span class="p">&gt;</span> <span class="kt">i32</span> <span class="p">{</span>
    <span class="nv">%0</span> <span class="p">=</span> <span class="err">arith</span><span class="p">.</span><span class="err">addi</span> <span class="nv">%arg0</span><span class="p">,</span> <span class="nv">%arg1</span> <span class="err">:</span> <span class="kt">i32</span>
    <span class="err">func</span><span class="p">.</span><span class="err">return</span> <span class="nv">%0</span> <span class="err">:</span> <span class="kt">i32</span>
<span class="p">}</span>
</code></pre></div></div> <p>Here, <code class="language-plaintext highlighter-rouge">arith.addi</code> does the heavy lifting. It grabs <code class="language-plaintext highlighter-rouge">%arg0</code> and <code class="language-plaintext highlighter-rouge">%arg1</code>, adds them up, and assigns the result to <code class="language-plaintext highlighter-rouge">%0</code>. Since every function block needs to end explicitly, we then use the <code class="language-plaintext highlighter-rouge">func.return</code> operation to send that <code class="language-plaintext highlighter-rouge">%0</code> value back out.</p> <p>Go ahead and save this code in a file called <code class="language-plaintext highlighter-rouge">add.mlir</code>. Next, we are going to use the <code class="language-plaintext highlighter-rouge">mlir-opt</code> tool to lower our high-level dialects (<code class="language-plaintext highlighter-rouge">func</code> and <code class="language-plaintext highlighter-rouge">arith</code>) down to the LLVM Dialect. If that sounds confusing, don’t worry, it tripped me up at first, too. You might be wondering: Why are we translating to an ‘LLVM dialect’ inside MLIR instead of just spitting out actual LLVM IR? &gt; That question actually hits on the entire purpose of MLIR. By keeping LLVM instructions represented as an MLIR dialect, the framework can preserve high-level structure and debug information during the translation process. The ultimate goal for almost any MLIR pipeline is to gradually step down the abstraction ladder until you hit this LLVM dialect. Once you are there, escaping out to standard LLVM IR is trivial.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlir-opt add.mlir <span class="nt">--convert-arith-to-llvm</span> <span class="nt">--convert-func-to-llvm</span> <span class="o">&gt;</span> add.llvm.mlir
</code></pre></div></div> <p>So, what is happening with this command?</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>func  ----
          \____ llvm
arith ----/
</code></pre></div></div> <p>As mentioned earlier, this process is called <strong>Lowering</strong>, where we are taking a MLIR program written using <code class="language-plaintext highlighter-rouge">func</code> and <code class="language-plaintext highlighter-rouge">arith</code> dialects and lower them into a single, lower-level dialect-<code class="language-plaintext highlighter-rouge">llvm</code>. You can use <code class="language-plaintext highlighter-rouge">mlir-opt --help</code> to look into all other possible <code class="language-plaintext highlighter-rouge">mlir-opt</code> flags.</p> <p>Now, ensure that you have the file <code class="language-plaintext highlighter-rouge">add.llvm.mlir</code>, which contains the translated code in the LLVM dialect as follows:</p> <div class="language-llvm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">module</span> <span class="p">{</span>
  <span class="err">llvm</span><span class="p">.</span><span class="err">func</span> <span class="vg">@add</span><span class="p">(</span><span class="nv">%arg0</span><span class="err">:</span> <span class="kt">i32</span><span class="p">,</span> <span class="nv">%arg1</span><span class="err">:</span> <span class="kt">i32</span><span class="p">)</span> <span class="err">-</span><span class="p">&gt;</span> <span class="kt">i32</span> <span class="p">{</span>
    <span class="nv">%0</span> <span class="p">=</span> <span class="err">llvm</span><span class="p">.</span><span class="k">add</span> <span class="nv">%arg0</span><span class="p">,</span> <span class="nv">%arg1</span> <span class="err">:</span> <span class="kt">i32</span>
    <span class="err">llvm</span><span class="p">.</span><span class="err">return</span> <span class="nv">%0</span> <span class="err">:</span> <span class="kt">i32</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <p>At first glance, it looks almost identical. But look closely at the prefixes. Every operation has shifted from a high-level abstraction to a specific LLVM instruction representation and now explictly wrapped in a <code class="language-plaintext highlighter-rouge">module</code>. In MLIR, operations cannot just float in the coid; they must live inside a block. Top-level operations like functions needs a container. The <code class="language-plaintext highlighter-rouge">module</code> operation acts as that container. Even though we did not explictly define a module ourselves, a <code class="language-plaintext highlighter-rouge">module</code> is implicit in MLIR programs which allows you to write top-level functions for convenience, but internally, it treats them as if they are inside a module. <code class="language-plaintext highlighter-rouge">module</code> defines a symbol table and creates a scope where global names (like <code class="language-plaintext highlighter-rouge">@add</code>) are defined and unique. This is roughly corresposnding to a translation unit in C++ or an object file. Our current program is entirly written using only one dialect-LLVM dialect and translated using <code class="language-plaintext highlighter-rouge">mlir-opt</code> as above.</p> <p>We are almost there. We have lowered out high-level logic into the low-level LLVM dialect. But here is the catch: we still cannot execute this. The machine does not know what MLIR is. It doesn’t know about dialects and operations. To run this, we need to leave the MLIR framework entirely and generate actual <strong>LLVM IR</strong>, the standard text-based format (<code class="language-plaintext highlighter-rouge">.ll</code>) that the LLVM backend understands.</p> <p>MLIR framework has a tool specifically for this purpose, <code class="language-plaintext highlighter-rouge">mlir-translate</code>. While <code class="language-plaintext highlighter-rouge">mlir-opt</code> is for transforming code within MLIR (optimization, lowering), <code class="language-plaintext highlighter-rouge">mlir-translate</code> is for exporting code out of MLIR. We will use <code class="language-plaintext highlighter-rouge">mlir-translate</code> to take out LLVM-dialect module and serialize it into valid LLVM IR using the following command:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mlir-translate <span class="nt">--mlir-to-llvmir</span> add.llvm.mlir <span class="nt">-o</span> add.ll
</code></pre></div></div> <p>If you open <code class="language-plaintext highlighter-rouge">add.ll</code>, you will see something familiar to any compiler engineer: standard, raw LLVM IR. We now have <code class="language-plaintext highlighter-rouge">add.ll</code>, which contains our <code class="language-plaintext highlighter-rouge">@add</code> function in valid LLVM IR. But if you try to compile it directly, nothing will happen. Why? Because we don’t have a <code class="language-plaintext highlighter-rouge">main</code> function. Every C/C++ (and LLVM) programs needs an entry point. Our <code class="language-plaintext highlighter-rouge">@add</code> function is just a library function right now; it’s waiting to be called, but nobody is calling it. Therefore, let’s create a simple driver program to fix this problem.</p> <p>driver.ll</p> <div class="language-llvm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">; Declare the external 'add' function (it exists in our other file)</span>
<span class="k">declare</span> <span class="kt">i32</span> <span class="vg">@add</span><span class="p">(</span><span class="kt">i32</span><span class="p">,</span> <span class="kt">i32</span><span class="p">)</span>

<span class="k">define</span> <span class="kt">i32</span> <span class="vg">@main</span><span class="p">()</span> <span class="p">{</span>
  <span class="c1">; Call 'add' with arguments 10 and 32</span>
  <span class="nv">%result</span> <span class="p">=</span> <span class="k">call</span> <span class="kt">i32</span> <span class="vg">@add</span><span class="p">(</span><span class="kt">i32</span> <span class="m">10</span><span class="p">,</span> <span class="kt">i32</span> <span class="m">32</span><span class="p">)</span>
  
  <span class="c1">; Return the result as the exit code</span>
  <span class="k">ret</span> <span class="kt">i32</span> <span class="nv">%result</span>
<span class="p">}</span>
</code></pre></div></div> <p>This is raw LLVM IR. It tells the compiler: “There is a function called <code class="language-plaintext highlighter-rouge">@add</code> somewhere else. I want to call it with <code class="language-plaintext highlighter-rouge">10</code> and <code class="language-plaintext highlighter-rouge">32</code>, and I want to return the answer as my program’s exit code.” Now that we have the <code class="language-plaintext highlighter-rouge">main</code> function too, let’s use <code class="language-plaintext highlighter-rouge">clang</code> to link them together into a real executable binary and run it.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>clang add.ll driver.ll <span class="nt">-o</span> add
./add
</code></pre></div></div> <p>But wait!, where is the output? If you run it, you won’t see anything. That’s expected! We didn’t tell the program to print anything (which requires library calls like <code class="language-plaintext highlighter-rouge">printf</code>). We told it to return the results as the exit code. To see the exit code in your terminal, run this:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./add <span class="p">;</span> <span class="nb">echo</span> <span class="nv">$?</span>
</code></pre></div></div> <p>If everything worked, you should see: <code class="language-plaintext highlighter-rouge">42</code></p> <p>Success! We did it. We started with high-level MLIR (func + arith), lowered it to the LLVM dialect, translated it to LLVM IR, linked it with a driver, and executed it on the bare metal.</p> <p>You have officially written, compiled, and run your first MLIR program.</p> <h3 id="create-mlir-pass">Create MLIR Pass</h3> <p>This is where things get real. Writing MLIR code (<code class="language-plaintext highlighter-rouge">.mlir</code>) is like writing Python, you are a user. Writing a Pass means writing C++, you are now a compiler engineer. In this section, we aren’t just running <code class="language-plaintext highlighter-rouge">mlir-opt</code>; we are building our own version of it. If you have used LLVM before, the traditional workflow: compile your pass into a shared library (<code class="language-plaintext highlighter-rouge">.so</code>) and then load it dynamically into the standard <code class="language-plaintext highlighter-rouge">opt</code> tool using a flag like <code class="language-plaintext highlighter-rouge">-load-pass-plugin</code>. In MLIR, we rarely do that. Instead, we almost always build our own custom version of <code class="language-plaintext highlighter-rouge">mlir-opt</code>.</p> <p>Why? Because, MLIR relies heavily on C++ templates and static registration. Because of how C++ templates work, they don’t play nice across library boundaries, trying to load an MLIR pass dynamically can lead to weird ABI issues or missing symbols. So the “MLIR Way” is to create a new C++ executable that links statically against the core MLIR libraries, the standard dialect libraries and our custom pass library. This results in a tool that functions exactly like <code class="language-plaintext highlighter-rouge">mlir-opt</code>, but extended to specifically include your pass.</p> <p>Let’s create a new directory for our “Hello World” MLIR pass called <code class="language-plaintext highlighter-rouge">PrintOpsPass</code> which can simply print the names of each operations. If you look at the C++ code for a pass, it can be intimidating. There are templates nested inside templates and macros with names that look like they were shouted by a compiler. But once you strip away the noise, it’s actually quite elegant.</p> <p>Create a file called <code class="language-plaintext highlighter-rouge">my-opt.cpp</code>, and start writing the pass by wrapping everything in an anonymous namespace (<code class="language-plaintext highlighter-rouge">namespace {...}</code>). In C++, this is a trick to make sure our class is only visible inside this specific file. We do this because eventually, we might link dozens of passes together into one tool, and we don’t want out <code class="language-plaintext highlighter-rouge">PrintOpsPass</code> colliding with someone else’s <code class="language-plaintext highlighter-rouge">PrintOpsPass</code>.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">using</span> <span class="k">namespace</span> <span class="n">mlir</span><span class="p">;</span>

<span class="k">namespace</span> <span class="p">{</span>
      <span class="k">struct</span> <span class="nc">PrintOpsPass</span> <span class="o">:</span> <span class="n">PassWrapper</span><span class="o">&lt;</span><span class="n">PrintOpsPass</span><span class="p">,</span> <span class="n">Operation</span><span class="o">&lt;</span><span class="n">ModuleOp</span><span class="o">&gt;&gt;</span> <span class="p">{}</span>
<span class="p">}</span>
</code></pre></div></div> <p>The above code defines our pass but at first glance it looks scary, especially, if you have not used <a href="https://en.wikipedia.org/wiki/Curiously_recurring_template_pattern" rel="external nofollow noopener" target="_blank">CRTP</a>(Curiously Recurring Template Pattern) in C++ before. Let’s look into it to clear away all the noise. We are defining our pass by inheriting from <code class="language-plaintext highlighter-rouge">PassWrapper</code>. This is a helper class MLIR provides to handle all the boilerplate of registering a pass. Also, notice the template arguments: <code class="language-plaintext highlighter-rouge">PrintOpsPass</code> and <code class="language-plaintext highlighter-rouge">OperationPass&lt;ModuleOp&gt;</code>. We are defining struct <code class="language-plaintext highlighter-rouge">PrintOpsPass</code>, but we are passing <code class="language-plaintext highlighter-rouge">PrintOpsPass</code> as a template argument to its own parent! This is known as the <strong>CRTP</strong>.</p> <p>In standard C++ OOP, runtime polymorphism is typically implemented using virtual functions, which introduce indirection via vtable lookups. While this overhead is negligible in most applications, it can be significant in compiler hot paths that execute at scale. Therefore we are passing <code class="language-plaintext highlighter-rouge">PrintOpsPass</code> into <code class="language-plaintext highlighter-rouge">PassWrapper</code> to give the parent class a compile-time pointer to its child. This allows <code class="language-plaintext highlighter-rouge">PassWrapper</code> to implement boilerplate methods (like <code class="language-plaintext highlighter-rouge">clone()</code> or <code class="language-plaintext highlighter-rouge">getId()</code>) for us, specifically customized for our class, without needing a single virtual function call. This is called static polymorphism.</p> <p>The second argument we are passing to the <code class="language-plaintext highlighter-rouge">PassWrapper</code> is called Traits. In MLIR, capabilities are often injected via these template arguments. This specific trait defines the behavioural constraints of your pass. By adding the <code class="language-plaintext highlighter-rouge">OperationPass</code> trait, we are telling the framework; “This pass is designed to run on specific operations.”. Also by specializing it with <code class="language-plaintext highlighter-rouge">&lt;ModuleOp&gt;</code>, we are adding a constraint; “This pass only works on <code class="language-plaintext highlighter-rouge">Module</code> operations.” If you tried to run this pass on a standard function, the compiler (via this trait) would know it’s illegal before the code even runs.</p> <p>Now that we have created the basic class structure, we need to give our pass a unique identity and wire it up so we can actually trigger it from the commandline.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="nc">PrintOpsPass</span> <span class="o">:</span> <span class="n">PassWrapper</span><span class="o">&lt;</span><span class="n">PrintOpsPass</span><span class="p">,</span> <span class="n">OperationPass</span><span class="o">&lt;</span><span class="n">ModuleOp</span><span class="o">&gt;&gt;</span> <span class="p">{</span>
    <span class="c1">// This creates a unique id for the pass</span>
    <span class="n">MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID</span><span class="p">(</span><span class="n">PrintOpsPass</span><span class="p">);</span>

    <span class="n">StringRef</span> <span class="n">getArgument</span><span class="p">()</span> <span class="k">const</span> <span class="k">override</span> <span class="p">{</span> <span class="k">return</span> <span class="s">"print-opt"</span><span class="p">;</span> <span class="p">}</span>
    <span class="n">StringRef</span> <span class="n">getDescription</span><span class="p">()</span> <span class="k">const</span> <span class="k">override</span> <span class="p">{</span> <span class="k">return</span> <span class="s">"This is a pass that will print the operation names. This is a analysis pass."</span><span class="p">;</span> <span class="p">}</span>
<span class="p">};</span>
</code></pre></div></div> <ul> <li> <code class="language-plaintext highlighter-rouge">MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID</code>, will inject a static variable into our pass class that will exist at a unique memory address in our program. MLIR then uses that raw memory address as the unique identifier for our pass.</li> <li> <code class="language-plaintext highlighter-rouge">getArgument()</code>, hooks our C++ code directly into the compiler’s commandline parser. Later, when we compile out tool, we will be able to trigger this exact C++ class just by typing <code class="language-plaintext highlighter-rouge">./our-custom-mlir-opt --print-opt</code> in the terminal.</li> <li> <code class="language-plaintext highlighter-rouge">getDescription()</code>, hooks its string argument automatically into the <code class="language-plaintext highlighter-rouge">--help</code> menu. If someone runs <code class="language-plaintext highlighter-rouge">./out-custom-mlir-opt --help</code>, the MLIR framework will automatically list <code class="language-plaintext highlighter-rouge">--print-opt</code> right next to this description.</li> </ul> <p>Finally, we reach the heart of the pass, the <code class="language-plaintext highlighter-rouge">runOnOperation()</code> method. If the metadata above is how we trigger the pass from the command line, <code class="language-plaintext highlighter-rouge">runOnOperation()</code> is what actually executes when that trigger is pulled.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">struct</span> <span class="nc">PrintOpsPass</span> <span class="o">:</span> <span class="n">PassWrapper</span><span class="o">&lt;</span><span class="n">PrintOpsPass</span><span class="p">,</span> <span class="n">OperationPass</span><span class="o">&lt;</span><span class="n">ModuleOp</span><span class="o">&gt;&gt;</span> <span class="p">{</span>
    <span class="c1">// ... (metadata stuff we just wrote) ...</span>

    <span class="c1">// pass logic</span>
    <span class="kt">void</span> <span class="n">runOnOperation</span><span class="p">()</span> <span class="k">override</span> <span class="p">{</span>
        <span class="c1">// getOperation() returns the top-level ops that this pass is running on (Usually the Module)</span>
        <span class="c1">// .walk() automatically iterates through every nested operation inside it</span>
        <span class="n">getOperation</span><span class="p">()</span><span class="o">-&gt;</span><span class="n">walk</span><span class="p">([](</span><span class="n">Operation</span> <span class="o">*</span><span class="n">op</span><span class="p">){</span>
            <span class="n">llvm</span><span class="o">::</span><span class="n">outs</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="s">"Visiting Op: "</span> <span class="o">&lt;&lt;</span> <span class="n">op</span><span class="o">-&gt;</span><span class="n">getName</span><span class="p">()</span> <span class="o">&lt;&lt;</span> <span class="s">";</span><span class="se">\n</span><span class="s">"</span><span class="p">;</span>
        <span class="p">});</span>
    <span class="p">}</span>
<span class="p">};</span>
</code></pre></div></div> <p>The first thing we do is call <code class="language-plaintext highlighter-rouge">getOperation()</code>. Because we told the framework earlier that this is an <code class="language-plaintext highlighter-rouge">OperationPass&lt;ModulePass&gt;</code>, this call comes with a guarantee that it will return top-level <code class="language-plaintext highlighter-rouge">Module</code> operation that acts as the container for our entire program.</p> <p>Next we need to look at every single operation inside that module. Remember, an MLIR program is structured like a massive tree: Modules contain Functions, Functions contain Blocks, and Blocks contain Operations (which might contain even more Blocks!). For this purpose, MLIR gives us the <code class="language-plaintext highlighter-rouge">.walk()</code> utility. Finally, we do a simple print to grab the operation’s name.</p> <p>Now we have our basic pass, but it’s just a C++ class floating in the coid. To actually run it against our previous <code class="language-plaintext highlighter-rouge">add.mlir</code> file, we need to build an executable.</p> <p>Remember earlier when we talked about building our own custom version of <code class="language-plaintext highlighter-rouge">mlir-opt</code>? We aren’t actually compiling a shared library to plug into an existing tool; we are compiling a brand new, standalone compiler tool from scratch. To do that we need a <code class="language-plaintext highlighter-rouge">main()</code> function. You can put this right at the bottom of the same C++ file.</p> <div class="language-cpp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include</span> <span class="cpf">"mlir/InitAllDialects.h"</span><span class="cp">
#include</span> <span class="cpf">"mlir/InitAllPasses.h"</span><span class="cp">
#include</span> <span class="cpf">"mlir/Pass/PassManager.h"</span><span class="cp">
#include</span> <span class="cpf">"mlir/Tools/mlir-opt/MlirOptMain.h"</span><span class="cp">
</span>
<span class="k">using</span> <span class="k">namespace</span> <span class="n">mlir</span><span class="p">;</span>
<span class="c1">// ... (our PrintOpsPass struct is up here) ...</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// create a registry and load all standard MLIR dialects</span>
    <span class="n">DialectRegistry</span> <span class="n">registry</span><span class="p">;</span>
    <span class="n">registerAllDialects</span><span class="p">(</span><span class="n">registry</span><span class="p">);</span>

    <span class="c1">// register our custom pass with the command line parser</span>
    <span class="n">PassRegistration</span><span class="o">&lt;</span><span class="n">PrintOpsPass</span><span class="o">&gt;</span><span class="p">();</span>

    <span class="c1">// run the tool (handles command line arguments, parsing, etc.)</span>
    <span class="k">return</span> <span class="n">asMainReturnCode</span><span class="p">(</span>
        <span class="n">MlirOptMain</span><span class="p">(</span><span class="n">argc</span><span class="p">,</span> <span class="n">argv</span><span class="p">,</span> <span class="s">"My Custom MLIR Optimizer"</span><span class="p">,</span> <span class="n">registry</span><span class="p">)</span>
    <span class="p">);</span>
<span class="p">}</span>
</code></pre></div></div> <p>This looks surprisingly short for a custom compiler tool, right? That is the beauty of MLIR’s modular design.</p> <p>When our tool reads the <code class="language-plaintext highlighter-rouge">add.mlir</code> file, it is going to encounter operations like <code class="language-plaintext highlighter-rouge">func.func</code> and <code class="language-plaintext highlighter-rouge">arith.addi</code>. If we don’t explicitly teach our tool what <code class="language-plaintext highlighter-rouge">func</code> and <code class="language-plaintext highlighter-rouge">arith</code> mean, it will throw a parsing error immediately. By creating a <code class="language-plaintext highlighter-rouge">DialectRegistry</code> and calling <code class="language-plaintext highlighter-rouge">registerAllDialects</code>, we are loading the definitions of every standard in-tree MLIR dialect into out tool’s memory.</p> <p>After registering all in-tree dialects, we have to register our custom pass using the <code class="language-plaintext highlighter-rouge">PassRegistration&lt;&gt;()</code>, so that the commandline parser would know to trigger our pass function when user gives <code class="language-plaintext highlighter-rouge">--print-opt</code> flag.</p> <p>Finally, the most important part, <code class="language-plaintext highlighter-rouge">MlirOptMain</code>. We could manually write the code to open a <code class="language-plaintext highlighter-rouge">.mlir</code> file, read the text, parse it into an MLIR module, initilize a Pass Manager, schedule our pass, catch errors and print the output back to terminal. But that would take a hundreds of lines of tedious boilerplate. Instead, MLIR provides <code class="language-plaintext highlighter-rouge">MlirOptMain</code>. We just hand it our commandline arguments (<code class="language-plaintext highlighter-rouge">argc</code>,<code class="language-plaintext highlighter-rouge">argv</code>) and our loaded registry. It takes over, acts exactly like the standard <code class="language-plaintext highlighter-rouge">mlir-opt</code> tool we used earlier, and handles all the file I/O and threading for us automatically.</p> <p>We have our C++ pass, and we have our driver. Now we just need to compile it. If you have spent any time in C++ compiler engineering, you know what time it is: CMake time. I won’t bore you with a deep dive into CMake syntax—our focus is on the IR, not the build system. Assuming you saved all that C++ code we just wrote into a file named <code class="language-plaintext highlighter-rouge">my-opt.cpp</code>, here is the <code class="language-plaintext highlighter-rouge">CMakeLists.txt</code> file you need to tie everything together.</p> <div class="language-cmake highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cmake_minimum_required</span><span class="p">(</span>VERSION 3.13<span class="p">)</span>
<span class="nb">project</span><span class="p">(</span>my-opt<span class="p">)</span>

<span class="nb">find_package</span><span class="p">(</span>MLIR REQUIRED CONFIG<span class="p">)</span>

<span class="nb">list</span><span class="p">(</span>APPEND CMAKE_MODULE_PATH <span class="si">${</span><span class="nv">MLIR_CMAKE_DIR</span><span class="si">}</span><span class="p">)</span>
<span class="nb">list</span><span class="p">(</span>APPEND CMAKE_MODULE_PATH <span class="si">${</span><span class="nv">LLVM_CMAKE_DIR</span><span class="si">}</span><span class="p">)</span>

<span class="nb">include</span><span class="p">(</span>TableGen<span class="p">)</span>
<span class="nb">include</span><span class="p">(</span>AddLLVM<span class="p">)</span>
<span class="nb">include</span><span class="p">(</span>AddMLIR<span class="p">)</span>
<span class="nb">include</span><span class="p">(</span>HandleLLVMOptions<span class="p">)</span>

<span class="nb">include_directories</span><span class="p">(</span><span class="si">${</span><span class="nv">LLVM_INCLUDE_DIR</span><span class="si">}</span><span class="p">)</span>
<span class="nb">include_directories</span><span class="p">(</span><span class="si">${</span><span class="nv">MLIR_INCLUDE_DIR</span><span class="si">}</span><span class="p">)</span>
<span class="nb">link_directories</span><span class="p">(</span><span class="si">${</span><span class="nv">LLVM_LIBRARY_DIR</span><span class="si">}</span><span class="p">)</span>
<span class="nb">add_definitions</span><span class="p">(</span><span class="si">${</span><span class="nv">LLVM_DEFINITIONS</span><span class="si">}</span><span class="p">)</span>

<span class="c1"># Define our executable</span>
<span class="nb">add_executable</span><span class="p">(</span>my-opt my-opt.cpp<span class="p">)</span>

<span class="nf">llvm_update_compile_flags</span><span class="p">(</span>my-opt<span class="p">)</span>

<span class="c1"># Link the necessary MLIR libraries</span>
<span class="c1"># We need MlirOptLib for the main entry point, and the others for IR/Passes.</span>
<span class="nb">target_link_libraries</span><span class="p">(</span>my-opt PRIVATE
  MLIRIR
  MLIRSupport
  MLIRPass
  MLIROptLib    <span class="c1"># contains MlirOptMain</span>
  MLIRRegisterAllDialects    <span class="c1"># contains standard dialects</span>
  MLIRRegisterAllPasses      <span class="c1"># contains standard passes</span>
<span class="p">)</span>
</code></pre></div></div> <p>While we are skipping a line-by-line breakdown, pay attention to the <code class="language-plaintext highlighter-rouge">target_link_libraries</code> at the bottom. This is where the magic happens. We are taking our tiny, custom <code class="language-plaintext highlighter-rouge">my-opt</code> executable and linking it against the massive, pre-compiled MLIR libraries (like <code class="language-plaintext highlighter-rouge">MLIRIR</code> and <code class="language-plaintext highlighter-rouge">MLIROptLib</code>).</p> <p>Once you have this boilerplate working, save it. You can reuse this exact setup later when you graduate from simple analysis passes to building more complex projects.</p> <p>Let’s finally build. Open your terminal in the diretory containing your <code class="language-plaintext highlighter-rouge">my-opt.cpp</code> and <code class="language-plaintext highlighter-rouge">CMakeLists.txt</code>, and run the standard CMake build command (Don’t forget to use the <code class="language-plaintext highlighter-rouge">load-llvm-dev</code> to load the installed LLVM from the previous section):</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir </span>build
<span class="nb">cd </span>build
cmake ..
make
</code></pre></div></div> <p>If everything is linked correctly to your LLVM installation, you should now have a shiny new executable named <code class="language-plaintext highlighter-rouge">my-opt</code> sitting in your build folder. Let’s use our custom tool to compile the <code class="language-plaintext highlighter-rouge">add.mlir</code> from earlier.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./my-opt --print-opt ./add.mlir -o /dev/null
</code></pre></div></div> <p>Because our compiler tool inherits from MLIR’s core infrastructure, it acts exactly like the standard <code class="language-plaintext highlighter-rouge">mlir-opt</code>. By default, it will take the input file, run our pass, and then print the entire resulting MLIR code back to the terminal. Since we only want to see our pass’s analysis log and not a giant wall of MLIR code, we use <code class="language-plaintext highlighter-rouge">-o /dev/null</code> to tell the tool to quietly discard the final IR output.</p> <p>When you run it, your terminal should output exactly what we asked for:</p> <pre><code class="language-txt">Visiting Op: builtin.module;
Visiting Op: func.func;
Visiting Op: arith.addi;
Visiting Op: func.return;
</code></pre> <p><strong>Success!!!</strong></p> <p>Our custom tool successfully parsed the <code class="language-plaintext highlighter-rouge">.mlir</code> file, walked the AST from top-level module all the way down to the individual arithmetic instructions, and execute our custom C++ logic at every node.</p> <h3 id="build-mlir-dialects">Build MLIR Dialects</h3> </div> </article> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"KabilanMA/kabilan","data-repo-id":"R_kgDOM8PKcQ","data-category":"compiler-comment","data-category-id":"DIC_kwDOM8PKcc4CpsbE","data-mapping":"pathname","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"top","data-theme":giscusTheme,"data-lang":"en","data-loading":"lazy",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,a])=>giscusScript.setAttribute(t,a)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Kabilan Mahathevan. Last updated: February 14, 2026. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"Publications",description:"publications by categories in reversed chronological order.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"Projects",description:"A growing collection of my projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-blogs",title:"Blogs",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-cv",title:"CV",description:"Click the PDF download button to download the CV.",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-hello-world-in-mlir",title:"Hello World in MLIR",description:"Start writing with MLIR",section:"Posts",handler:()=>{window.location.href="/blog/2026/MLIR-2/"}},{id:"post-intro-to-mlir",title:"Intro to MLIR",description:"Information needed to create a setup for MLIR and LLVM.",section:"Posts",handler:()=>{window.location.href="/blog/2026/MLIR-1/"}},{id:"post-compilers",title:"Compilers",description:"A Record Keeping of Compiler Learning Materials",section:"Posts",handler:()=>{window.location.href="/blog/2025/compiler/"}},{id:"post-from-atheist-to-believer",title:"From Atheist to Believer",description:"This is a Story Happened in My Personal Life Which Changed My Perspective",section:"Posts",handler:()=>{window.location.href="/blog/2025/ghost-story/"}},{id:"post-gnu-debugger-gdb-quick-notes",title:"GNU Debugger (GDB) Quick Notes",description:"This contains the basic informations about using GNU debugger for C/C++ programs.",section:"Posts",handler:()=>{window.location.href="/blog/2025/gdb/"}},{id:"post-an-image-gallery-of-chongqing-china",title:"An Image Gallery of Chongqing, China",description:"This is about my visit to Chongqing for APSEC 2024 conference.",section:"Posts",handler:()=>{window.location.href="/blog/2024/apsec2024/"}},{id:"news-started-working-as-software-engineer-at-sysco-labs-https-syscolabs-lk",title:"Started working as Software Engineer at [Sysco LABS](https://syscolabs.lk/)",description:"",section:"News"},{id:"news-started-working-as-visiting-scholar-at-nus",title:"Started working as Visiting Scholar at NUS.",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-the-paper-bugsinkube-a-collection-of-reconciliation-bugs-assets-pdf-bugsinkube-pdf-got-accepted-to-apsec-2024",title:"The paper [BugsInKube: A Collection of Reconciliation Bugs](assets/pdf/BugsInKube.pdf) got accepted to APSEC 2024....",description:"",section:"News"},{id:"news-joined-the-artifact-evaluation-committee-at-fast-39-25-https-www-usenix-org-conference-fast25-call-for-artifacts",title:"Joined the artifact evaluation committee at [FAST&#39;25](https://www.usenix.org/conference/fast25/call-for-artifacts)",description:"",section:"News"},{id:"news-presented-a-paper-in-apsec-2024",title:"Presented a paper in APSEC-2024",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_5/"}},{id:"news-started-phd-in-cs-at-virginia-tech-https-www-vt-edu",title:"Started PhD in CS at [Virginia Tech](https://www.vt.edu/)",description:"",section:"News"},{id:"news-the-paper-tensure-fuzzing-sparse-tensor-compilers-assets-pdf-tensure-fuzzing-pdf-got-accepted-to-fuzzing-39-26-ndss-2026",title:"The paper [TENSURE: Fuzzing Sparse Tensor Compilers](assets/pdf/tensure_fuzzing.pdf) got accepted to Fuzzing&#39;26 (NDSS) 2026....",description:"",section:"News"},{id:"projects-tensure",title:"TenSure",description:"Sparse Tensor Compiler Fuzzer",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-bugsinkube",title:"BugsInKube",description:"Bug Inspector Toolkit",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-p2p-tc",title:"P2P TC",description:"A Commandline P2P Torrent Client",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=Qqy6DvYAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/kabilanma","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/kabilan-dev","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/KabilanMahathev","_blank")}},{id:"socials-medium",title:"Medium",section:"Socials",handler:()=>{window.open("https://medium.com/@kabilanMahathevan","_blank")}},{id:"socials-facebook",title:"Facebook",section:"Socials",handler:()=>{window.open("https://facebook.com/mahathevan.kabilan","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>